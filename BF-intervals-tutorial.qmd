---
title: "Bayes factors for interval hypotheses: A tutorial"
author: "Timo Roettger & Michael Franke"
format: 
  html:
    code-fold: true
    self-contained: true
    highlight-style: atom-one
    theme:
      light: materia
      dark: darkly
execute:
  error: false
  warning: false
  message: false
  cache: true
editor:
  markdown:
    wrap: sentence
---

# Preamble: Loading packages and configuration

First load required packages and set some global parameters.

```{r loads-preps}
#| echo: true
#| error: false
#| warning: false
#| message: false

####################
## install packages
#####################

# package for convenience functions (e.g. plotting)
library(tidyverse)

# package for Bayesian regression modeling
library(brms)

# package for posterior wrangling and plotting
library(tidybayes)

# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())

# package for credible interval computation
library(HDInterval)

# set the random seed in order to make sure
# you can reproduce the same results
set.seed(1702)

# project colors
project_colors = c(
  "#7581B3", "#99C2C2", "#C65353", "#E2BA78", "#5C7457", "#575463",
  "#B0B7D4", "#66A3A3", "#DB9494", "#D49735", "#9BB096", "#D4D3D9",
  "#414C76", "#993333"
  )
```

# Read & inspect the data

Read the data to be analyzed and inspect it.

```{r read-data}
#| warning: false
#| message: false

##################
## load the data
##################

# load the data into variable "politedata"
politedata = read_csv("https://raw.githubusercontent.com/michael-franke/bayes_mixed_regression_tutorial/master/code/politeness_data.csv")

# inspect head of data
head(politedata)

# only female speakers
politeF <- politedata |> 
  filter(gender == "F") |> 
  # calculate semitones (because JND literature is usually in semitones and it reflects perception better than hz)
  mutate(pitch_ST = 12 * log2(pitch / 50))

```


```{r read-alt_data}
#| warning: false
#| message: false

# load full dataset

# function to ignoring the setting of the relative path below when knitting
run_if_not_knitting <- function(expr) {
  if (!isTRUE(getOption("knitr.in.progress"))) {
    eval(expr)
  }
}

# set the current working directory to the one where this file is
run_if_not_knitting(current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path))
run_if_not_knitting(setwd(current_working_dir))
polite = read_csv("data/polite.csv")

# only female speakers
politeF <- polite |> 
  filter(gender == "F") |> 
  # calculate semitones
  mutate(pitch_ST = 12 * log2(pitch / 50))

# check
table(politeF$subject, politeF$context)

```

```{r data-plot-basic}

politedata.agg <- 
  politeF %>% 
  group_by(context, subject) %>% 
  summarize(mean_frequency = mean(pitch_ST))

politedata.agg2 <- 
  politeF %>%
  group_by(context) %>% 
  summarize(mean_frequency = mean(pitch_ST, na.rm = TRUE))

ggplot(data = politedata.agg, 
       aes(x = context, 
           y = mean_frequency, 
           colour = context)) + 
  geom_point(position = position_dodge(0.5), 
             alpha = 0.5, 
             size = 3) +
  geom_point(data = politedata.agg2, 
             aes(x = context, 
                 y = mean_frequency, 
                 fill = context),
             position = position_dodge(0.5), 
             pch = 21, 
             colour = "black",
             size = 5) +
  scale_colour_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  scale_fill_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  ylab("pitch in semitones\n") +
  xlab("\nsocial context") +
  theme_minimal()

```

# Run regression

Run a simple multilinear regression analysis.

```{r priors}
#| output: false

# formula
formula <- bf(pitch_ST ~ context + (1 + context | subject))

# get prior
get_prior(formula, politeF)

# close to default priors which are uninformed but sensible
priors <- c(prior(normal(28, 2), class = Intercept),
            prior(normal(0, 1), class = b, coef = "contextinformal"),
            prior(lkj(2), class = cor),
            prior(normal(0, 2), class = sd))

```

```{r regression}
#| output: false

options(mc.cores = parallel::detectCores())

fit <- brm(formula,
           prior = priors,
           family = gaussian(),
           # common sampling specifications
           seed = 1234,
           file  = "models/fit",
           iter = 4000,
           chains = 4,
           cores = 4,
           backend = "cmdstanr",
           data = politeF)

```

Look at the summary:

```{r regression-summary}

summary(fit)

```

Posterior predictive check:

```{r posterior-predictive}

pp_check(fit, ndraws = 100)

```

Plot posteriors:

```{r plot-posterior}

fit |> 
  spread_draws(b_contextinformal) |> 
  ggplot(aes(x = b_contextinformal)) +
    geom_density(fill = project_colors[2],
                 alpha = 0.8) +
    xlab("pitch difference in semitones\n") +
    theme_minimal()

```

Run prior-only model:

```{r regression-priors-only}
#| output: false

fit_null <- brm(formula,
           prior = priors,
           family = gaussian(),
           # sample prior only
           sample_prior = "only",
           # common sampling specifications
           seed = 1234,
           file  = "models/fit_null",
           iter = 4000,
           chains = 4,
           cores = 4,
           backend = "cmdstanr",
           data = politeF)

```

# ROPEs and Bayes Factor

Define a region of practical equivalence. Here we pick a lenient ROPE: According to t'Hart (1981), the average JNDâ€™s for pitch perception in speech is about 1.5 to 2. A more conservative ROPE would be a semitone difference of 3 which according to t'Hart "only differences of more than 3 semitones play a part in communicative situations"

```{r define-rope}

ropes <- tibble(x = -1.5,
                y = 1.5)

```

Plot posterior distributions of full and null model, highlighting the samples within the ROPE:

```{r plot-samples-in-rope}

# extract prior-only posteriors
fit_prior <- fit_null |> 
  spread_draws(b_contextinformal) |> 
  mutate(model = "prior only")

# extract full model posteriors
fit_posterior <- fit |> 
  spread_draws(b_contextinformal) |> 
  mutate(model = "posterior")

# merge with full model
fit_all <- 
  full_join(fit_prior,fit_posterior) 

# extract densities from posterior distributions
plot_prior <- data.frame(density(fit_prior$b_contextinformal)[c("x", "y")]) |> 
  mutate(model = "prior")
plot_posterior <- data.frame(density(fit_posterior$b_contextinformal)[c("x", "y")]) |> 
  mutate(model = "posterior")
plot_all <- 
  full_join(plot_prior,plot_posterior) 

# plot
ggplot(plot_all, aes(x, y)) + 
      facet_wrap(model ~ ., nrow = 2,
                 strip.position = "right") +
      geom_area(data = plot_all |> filter(x >= ropes[[1]] & x <= ropes[[2]]), 
                fill = project_colors[14]) +
      geom_area(data = plot_all |> filter(x < ropes[[1]]), 
                fill = project_colors[2]) +
      geom_area(data = plot_all |> filter(x > ropes[[2]]), 
                fill = project_colors[2]) +
      geom_vline(xintercept = c(ropes[[1]], ropes[[2]]),
               lty = "dashed") +
      labs(x = "\npredicted pitch difference in semitones\n",
           y = "") +
      theme_minimal()


```

An alternative visualization would be a quantile dot plot. Intuitive for pedagogic purposes: The BF is basically the amount of red dots of posterior model divided by the amount of red dots of prior model

```{r dots-plot-with-rope}


fit_all |> 
  ggplot(aes(x = b_contextinformal, y = model, fill = after_stat(x >= ropes[[1]] & x <= ropes[[2]]))) +
  stat_dots(quantiles = 100, 
            color = NA) +
  labs(x = "\npredicted pitch difference in semitones\n",
       y = "",
       fill = "") +
  scale_fill_manual(values = c(project_colors[2], project_colors[14]),
                    labels = c("outside", "inside")) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  )


```

Calculate BF after Savage-Dickey which is pretty much 1, so very inconclusive evidence.

```{r extract-posteriors-rope}

# count samples in rope full model
posterior_prob <- fit %>% 
    spread_draws(b_contextinformal) |> 
    filter(b_contextinformal > ropes$x & b_contextinformal < ropes$y) |> 
    count()

# count samples in rope null model
prior_prob <- fit_null %>% 
    spread_draws(b_contextinformal) |> 
    filter(b_contextinformal > ropes$x & b_contextinformal < ropes$y) |> 
    count()

# BF after Savage-Dickey is pretty much 1
posterior_prob / prior_prob

```

# Loop through prior x rope combinations

This way of inference is dependent on both the priors of the relevant model parameters and the chosen ROPE. So ideally we run this analysis across a variety of sensible combinations of these two degrees of freedom. We chose sensible prior widths for the difference between formal and informal contexts (ranging from sd = 1 to sd = 3):

(Do not run)

```{r loop-priors-for-full-models}

# Define priors for all parameter except the critical one
priors <- c(prior(normal(28, 2), class = Intercept),
            prior(lkj(2), class = cor),
            prior(normal(0, 2), class = sd))

# define 5 different priors that make sense
priors_1 <- c(priors, 
              prior(normal(0, 1), class = b, coef = "contextinformal"))
priors_1.5 <- c(priors, 
              prior(normal(0, 1.5), class = b, coef = "contextinformal"))
priors_2 <- c(priors, 
              prior(normal(0, 2), class = b, coef = "contextinformal"))
priors_2.5 <- c(priors, 
              prior(normal(0, 2.5), class = b, coef = "contextinformal"))
priors_3 <- c(priors, 
              prior(normal(0, 3), class = b, coef = "contextinformal"))

# Define a list of these prior specifications
prior_list <- list(priors_1,
                   priors_1.5,
                   priors_2,
                   priors_2.5,
                   priors_3
)


# Initialize a list to store models
model_list <- list()

# Loop over the priors
# for (i in seq_along(prior_list)) {
#     model_list[[i]] <- 
#       brm(
#         formula = formula,
#         data = politeF,
#         prior = prior_list[[i]],
#         # common sampling specifications
#         seed = 1234,
#         iter = 4000,
#         chains = 4,
#         cores = 4,
#         backend = "cmdstanr"
#   )
# }

# name models
# names(model_list) <- paste0("full_model_with_prior_", c(1,1.5,2,2.5,3))

```

Same for null models:

(Do not run)

```{r loop-priors-for_null-models}

# Initialize a list to store models
model_list_null <- list()

# Loop over the priors
# for (i in seq_along(prior_list)) {
#     model_list_null[[i]] <- 
#       brm(
#         formula = formula,
#         sample_prior = "only",
#         data = politeF,
#         prior = prior_list[[i]],
#         # common sampling specifications
#         seed = 1234,
#         iter = 4000,
#         chains = 4,
#         cores = 4,
#         backend = "cmdstanr"
#   )
# }

# name models
#names(model_list_null) <- paste0("null_model_with_prior_", c(1,1.5,2,2.5,3))

```

```{r merge-model-dfs}

#model_list_all <- c(model_list, model_list_null)
#saveRDS(model_list_all, "models/model_loop.RDS")

model_list_all <- readRDS("models/model_loop.RDS")

```

Now that we have the models, we can loop through different ROPEs

```{r loop-through-ropes}

# Extract posterior draws for a specific parameter, e.g., "b_treatment"
# "b_" prefix is used by brms for fixed effects
target_param <- "b_contextinformal"

model_names <- names(model_list_all)  # Optional: give names

# Use imap (indexed map) to keep track of model names
posterior_draws <- imap_dfr(
  model_list_all,
    ~ spread_draws(.x, !!sym(target_param)) %>%
      mutate(model = model_names[.y]),
  .id = "model_id"
)

# wrangle 
posterior_draws <- posterior_draws |> 
  separate(model_id, sep = "_", into = c("model_type", NA, NA, NA, "prior_sd")) |> 
  select(-model, -.chain, -.iteration, -.draw)

# specify different rope intervals
ropes <- list(c(-3,3),
              c(-2.5,2.5),
              c(-2,2),
              c(-1.5,1.5),
              c(-1,1))

# loop through ranges and models
results <- map_dfr(ropes, ~{
  lower <- .x[1]
  upper <- .x[2]
  
  posterior_draws |> 
    group_by(model_type, prior_sd)  |> 
    summarise(
      prob_in_rope = mean(b_contextinformal >= lower & b_contextinformal <= upper),
      .groups = "drop"
    )  |> 
    mutate(rope = paste0("[", lower, ", ", upper, "]"))
})

# make wide and calculate bf after Savage-Dickey
results <- results |> 
  pivot_wider(names_from = model_type, values_from = prob_in_rope) |> 
  mutate(bayes_factor = full / null)

```

Visualize combination in raster:

```{r visualize-raster}

# plot raster

ggplot(results,
       aes(x = as.factor(prior_sd),
           y = as.factor(rope),
           fill = bayes_factor)) +
  geom_tile(colour = "grey") +
  geom_text(aes(label = round(bayes_factor,2))) +
  scale_fill_gradient2(limits = c(0,5), 
                      midpoint = 1, 
                      low = "#7581B3", 
                      high = "#FA8100") +
  labs(title = "(A) Bayes factor in favour of null", 
       subtitle = "anecdotal evidence for the null: inconclusive",
       fill = "BF",
       y = "ROPE in semi tones centered on 0\n ",
       x = "\nprior standard deviation") +
  theme_minimal()

```

Now if we do not test perceptual / function hypotheses about the pitch differences, we can be more liberal with the ROPE intervals. We might be interested in testing merely if there are differences in production regardless of whether they are consistently perceptible.

(not sure what to do here, could go standardized effect sizes and use cohens D of 0.1)

```{r loop-through-liberal-ropes}

# specify different rope intervals
ropes_liberal <- list(c(-0.5,0.5),
              c(-0.4,0.4),
              c(-0.3,0.4),
              c(-0.2,0.2),
              c(-0.1,0.1))

# loop through ranges and models
results_liberal <- map_dfr(ropes_liberal, ~{
  lower <- .x[1]
  upper <- .x[2]
  
  posterior_draws |> 
    group_by(model_type, prior_sd)  |> 
    summarise(
      prob_in_rope = mean(b_contextinformal >= lower & b_contextinformal <= upper),
      .groups = "drop"
    )  |> 
    mutate(rope = paste0("[", lower, ", ", upper, "]"))
})

# make wide and calculate bf after Savage-Dickey
results_liberal <- results_liberal |> 
  pivot_wider(names_from = model_type, values_from = prob_in_rope) |> 
  mutate(bayes_factor = full / null)

```

Visualize combination in raster:

```{r visualize_raster}

# plot raster

ggplot(results_liberal,
       aes(x = as.factor(prior_sd),
           y = as.factor(rope),
           fill = bayes_factor)) +
  geom_tile(colour = "grey") +
  geom_text(aes(label = round(bayes_factor,2))) +
  scale_fill_gradient2(limits = c(0,5), 
                      midpoint = 1, 
                      low = "#7581B3", 
                      high = "#FA8100") +
  labs(title = "(A) Bayes factor in favour of null", 
       subtitle = "anecdotal to moderate evidence against the null",
       fill = "BF",
       y = "ROPE in semi tones centered on 0\n ",
       x = "\nprior standard deviation") +
  theme_minimal()

```