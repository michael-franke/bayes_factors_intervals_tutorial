---
title: "Bayes factors for interval hypotheses: A tutorial"
author: "Timo Roettger & Michael Franke"
format: 
  html:
    code-fold: true
    self-contained: true
    highlight-style: atom-one
    theme:
      light: materia
      dark: darkly
execute:
  error: false
  warning: false
  message: false
  cache: true
editor:
  markdown:
    wrap: sentence
---

# Preamble: Loading packages and configuration

First load required packages and set some global parameters.

```{r loads-preps}
#| echo: true
#| error: false
#| warning: false
#| message: false

####################
## install packages
#####################

# package for convenience functions (e.g. plotting)
library(tidyverse)

# package for Bayesian regression modeling
library(brms)

# package for posterior wrangling and plotting
library(tidybayes)

# package for BF calculation and plotting
library(bayestestR)
library(see)

# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())

# package for credible interval computation
library(HDInterval)

# set the random seed in order to make sure
# you can reproduce the same results
set.seed(1702)

# project colors
project_colors = c(
  "#7581B3", "#99C2C2", "#C65353", "#E2BA78", "#5C7457", "#575463",
  "#B0B7D4", "#66A3A3", "#DB9494", "#D49735", "#9BB096", "#D4D3D9",
  "#414C76", "#993333"
  )
```

# Read & inspect the data

Read the data to be analyzed and inspect it.

```{r read-data}
#| warning: false
#| message: false

##################
## load the data
##################

# load the data into variable "politedata"
politedata = read_csv("https://raw.githubusercontent.com/michael-franke/bayes_mixed_regression_tutorial/master/code/politeness_data.csv")

# inspect head of data
head(politedata)

# only female speakers
politeF <- politedata |> 
  filter(gender == "F") |> 
  # calculate semitones (because JND literature is usually in semitones and it reflects perception better than hz)
  mutate(pitch_ST = 12 * log2(pitch / 50))

```


```{r read-alt_data}
#| warning: false
#| message: false

# load full dataset

# function to ignoring the setting of the relative path below when knitting
run_if_not_knitting <- function(expr) {
  if (!isTRUE(getOption("knitr.in.progress"))) {
    eval(expr)
  }
}

# set the current working directory to the one where this file is
run_if_not_knitting(current_working_dir <- dirname(rstudioapi::getActiveDocumentContext()$path))
run_if_not_knitting(setwd(current_working_dir))
polite = read_csv("data/polite.csv")

# only female speakers
politeF <- polite |> 
  filter(gender == "F") |> 
  # calculate semitones
  mutate(pitch_ST = 12 * log2(pitch / 50))

# check
table(politeF$subject, politeF$context)

```

```{r data-plot-basic}

politedata.agg2 <- 
  politeF %>%
  group_by(context) %>% 
  summarize(mean_frequency = mean(pitch_ST, na.rm = TRUE))


empirical <- 
ggplot(data = politeF, 
       aes(y= context, 
           x = pitch_ST, 
           fill = context,
           colour = context)) + 
  geom_point(position = position_dodge(0.5), 
             alpha = 0.5, 
             size = 3) +
  geom_density_ridges(alpha = 0.5,
                      scale = 0.5) +
  geom_point(data = politedata.agg2, 
             aes(y = context, 
                 x = mean_frequency, 
                 fill = context),
             position = position_dodge(0.5), 
             pch = 21, 
             colour = "black",
             size = 5) +

  scale_colour_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  scale_fill_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  labs(x = "\npitch in semitones",
       y = "social context\n") +
  theme_minimal() +
  theme(legend.position = "none")

empirical

```

# Run regression

Run a simple multi level regression analysis.

```{r priors}
#| output: false

# formula
formula <- bf(pitch_ST ~ context + (1 + context | subject))

# get prior
get_prior(formula, politeF)

# close to default priors which are uninformed but sensible
priors <- c(prior(normal(28, 2), class = Intercept),
            prior(normal(0, 1), class = b, coef = "contextinformal"),
            prior(lkj(2), class = cor),
            prior(normal(0, 2), class = sd))

```

```{r regression}
#| output: false

# question: sample number should be high for BFs, right?

fit <- brm(formula,
           prior = priors,
           family = gaussian(),
           # common sampling specifications
           seed = 1234,
           file  = "models/fit",
           iter = 4000,
           chains = 4,
           cores = 4,
           backend = "cmdstanr",
           data = politeF)

```

Look at the summary:

```{r regression-summary}

summary(fit)

```

Posterior predictive check:

```{r posterior-predictive}

pp_check(fit, ndraws = 100)

```

Plot posteriors:

```{r plot-posterior}

posteriors <- 
  fit |> 
  spread_draws(b_Intercept, b_contextinformal) |> 
  mutate(formal = b_Intercept,
         informal = b_Intercept + b_contextinformal) |> 
  select(formal, informal) |> 
  pivot_longer(cols = c(formal, informal),
               values_to = "pitch_ST", 
               names_to = "context") 

ggplot(data = posteriors, 
       aes(y= context, 
           x = pitch_ST, 
           fill = context,
           colour = context)) + 
  geom_density_ridges(alpha = 0.5,
                      scale = 0.5) +
  scale_colour_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  scale_fill_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  labs(x = "\npitch in semitones",
       y = "social context\n") +
  theme_minimal() +
  theme(legend.position = "none")

```

Run prior-only model:

```{r regression-priors-only}
#| output: false

fit_null <- brm(formula,
           prior = priors,
           family = gaussian(),
           # sample prior only
           sample_prior = "only",
           # common sampling specifications
           seed = 1234,
           file  = "models/fit_null",
           iter = 4000,
           chains = 4,
           cores = 4,
           backend = "cmdstanr",
           data = politeF)

```

# Simple Bayes Factor against a point null

Calculate BF using Savage-Dickey approximation against a point-0-hypothesis, in other words how much more evidence does a full model with information about the predictor provide over a model that is based on priors only:

```{r calculcate_SD_BF}

BF <- bayesfactor_parameters(fit, null = 0)
BF

```

The Bayes factor indicates 5.5 times more evidence for the null model over the alternative model. 

We can conveniently plot this using the `plot()` function of the `see` package. 

```{r visualize_BF_test}

plot(BF)

```

# ROPEs and Bayes Factor

Define a region of practical equivalence. Here we pick a lenient ROPE: According to t'Hart (1981), the average JNDâ€™s for pitch perception in speech is about 1.5 to 2. A more conservative ROPE would be a semitone difference of 3 which according to t'Hart "only differences of more than 3 semitones play a part in communicative situations"

```{r define-rope}

ropes <- c(-1.5, 1.5)

```

Plot posterior distributions of full and null model, highlighting the samples within the ROPE:

```{r plot-samples-in-rope}

# extract prior-only posteriors
fit_prior <- fit_null |> 
  spread_draws(b_contextinformal) |> 
  mutate(model = "prior only")

# extract full model posteriors
fit_posterior <- fit |> 
  spread_draws(b_contextinformal) |> 
  mutate(model = "posterior")

# merge with full model
fit_all <- 
  full_join(fit_prior,fit_posterior) 

# extract densities from posterior distributions
plot_prior <- data.frame(density(fit_prior$b_contextinformal)[c("x", "y")]) |> 
  mutate(model = "prior")
plot_posterior <- data.frame(density(fit_posterior$b_contextinformal)[c("x", "y")]) |> 
  mutate(model = "posterior")
plot_all <- 
  full_join(plot_prior,plot_posterior) 

# plot
ggplot(plot_all, aes(x, y)) + 
      facet_wrap(model ~ ., nrow = 2,
                 strip.position = "right") +
      geom_area(data = plot_all |> filter(x >= ropes[[1]] & x <= ropes[[2]]), 
                fill = project_colors[14]) +
      geom_area(data = plot_all |> filter(x < ropes[[1]]), 
                fill = project_colors[2]) +
      geom_area(data = plot_all |> filter(x > ropes[[2]]), 
                fill = project_colors[2]) +
      geom_vline(xintercept = c(ropes[[1]], ropes[[2]]),
               lty = "dashed") +
      labs(x = "\npredicted pitch difference in semitones\n",
           y = "") +
      theme_minimal()


```

An alternative visualization would be a quantile dot plot. Intuitive for pedagogic purposes: The BF is basically the amount of red dots of posterior model divided by the amount of red dots of prior model

```{r dots-plot-with-rope}


fit_all |> 
  ggplot(aes(x = b_contextinformal, y = model, fill = after_stat(x >= ropes[[1]] & x <= ropes[[2]]))) +
  stat_dots(quantiles = 100, 
            color = NA) +
  labs(x = "\npredicted pitch difference in semitones\n",
       y = "",
       fill = "") +
  scale_fill_manual(values = c(project_colors[2], project_colors[14]),
                    labels = c("outside", "inside")) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  )


```


```{r calculcate_SD_BF}

BF_ropes <- bayesfactor_parameters(fit, null = 0, parameters = "b_contextinformal")
BF_ropes

```

The Bayes factor indicates that 1.07 times more evidence for the null model over the alternative model. 

```{r visualize_BF_test}

plot(BF_ropes)

```


# Loop through prior x rope combinations

This way of inference is dependent on both the priors of the relevant model parameters and the chosen ROPE. So ideally we run this analysis across a variety of sensible combinations of these two degrees of freedom. We chose sensible prior widths for the difference between formal and informal contexts (ranging from sd = 1 to sd = 3):

(Do not run)

```{r loop-priors-for-full-models}

# Define priors for all parameter except the critical one
priors <- c(prior(normal(28, 2), class = Intercept),
            prior(lkj(2), class = cor),
            prior(normal(0, 2), class = sd))

# define 5 different priors widths that make sense
priors_1 <- c(priors, 
              prior(normal(0, 1), class = b, coef = "contextinformal"))
priors_1.5 <- c(priors, 
              prior(normal(0, 1.5), class = b, coef = "contextinformal"))
priors_2 <- c(priors, 
              prior(normal(0, 2), class = b, coef = "contextinformal"))
priors_2.5 <- c(priors, 
              prior(normal(0, 2.5), class = b, coef = "contextinformal"))
priors_3 <- c(priors, 
              prior(normal(0, 3), class = b, coef = "contextinformal"))

# Define a list of these prior specifications
prior_list <- list(priors_1,
                   priors_1.5,
                   priors_2,
                   priors_2.5,
                   priors_3
)


# Initialize a list to store models
model_list <- list()

# # Loop over the priors
# for (i in seq_along(prior_list)) {
#     model_list[[i]] <-
#       brm(
#         formula = formula,
#         data = politeF,
#         prior = prior_list[[i]],
#         # common sampling specifications
#         seed = 1234,
#         iter = 4000,
#         chains = 4,
#         cores = 4,
#         backend = "cmdstanr"
#   )
# }
# 
# # name models
# names(model_list) <- paste0("full_model_with_prior_", c(1,1.5,2,2.5,3))

```


```{r store-results}

#saveRDS(model_list, "models/model_loop.RDS")
model_list_all <- readRDS("models/model_loop.RDS")

```

Now that we have the models, we can loop through different ROPEs

```{r loop-through-ropes}

# specify different rope intervals
ropes <- list(c(-3,3),
              c(-2.5,2.5),
              c(-2,2),
              c(-1.5,1.5),
              c(-1,1))

results <- map_dfr(names(model_list_all), function(model_name) {
  model <- model_list_all[[model_name]]
  
  map_dfr(ropes, function(interval) {
    lower <- interval[1]
    upper <- interval[2]
    
    bayesfactor_parameters(
      model,
      null = c(lower, upper),
      parameter = "b_contextinformal"
    ) %>%
      as_tibble() %>%
      mutate(
        model = model_name,
        interval_range = paste0("[", lower, ", ", upper, "]")
      ) %>%
      select(model, everything())
  })
})


# wrangle
results <- results |> 
  filter(Parameter == "b_contextinformal") |> 
  separate(model, sep = "_", into = c(NA, NA, NA, NA, "prior_sd")) |> 
  mutate(BF = exp(log_BF)) |> 
  select(prior_sd, BF, interval_range)

```

Visualize combination in raster:

```{r visualize-raster}

# plot raster

ggplot(results,
       aes(x = as.factor(prior_sd),
           y = as.factor(interval_range),
           fill = BF)) +
  geom_tile(colour = "grey") +
  geom_text(aes(label = round(BF,2))) +
  scale_fill_gradient2(limits = c(0,10), 
                      midpoint = 1, 
                      low = "#7581B3", 
                      high = "#FA8100") +
  labs(title = "(A) Bayes factor in favour of null", 
       subtitle = "anecdotal evidence for the null: inconclusive",
       fill = "BF",
       y = "ROPE in semi tones centered on 0\n ",
       x = "\nprior standard deviation") +
  theme_minimal()

```

Now if we do not test perceptual / function hypotheses about the pitch differences, we can be more liberal with the ROPE intervals. We might be interested in testing merely if there are differences in production regardless of whether they are consistently perceptible.

(not sure what to do here, could go standardized effect sizes and use cohens D of 0.1)

```{r loop-through-liberal-ropes}

# specify different rope intervals
ropes_liberal <- list(c(-0.5,0.5),
              c(-0.4,0.4),
              c(-0.3,0.4),
              c(-0.2,0.2),
              c(-0.1,0.1))

# loop through ranges and models
results_liberal <- map_dfr(ropes_liberal, ~{
  lower <- .x[1]
  upper <- .x[2]
  
  posterior_draws |> 
    group_by(model_type, prior_sd)  |> 
    summarise(
      prob_in_rope = mean(b_contextinformal >= lower & b_contextinformal <= upper),
      .groups = "drop"
    )  |> 
    mutate(rope = paste0("[", lower, ", ", upper, "]"))
})

# make wide and calculate bf after Savage-Dickey
results_liberal <- results_liberal |> 
  pivot_wider(names_from = model_type, values_from = prob_in_rope) |> 
  mutate(bayes_factor = full / null)

```

Visualize combination in raster:

```{r visualize_raster}

# plot raster

ggplot(results_liberal,
       aes(x = as.factor(prior_sd),
           y = as.factor(rope),
           fill = bayes_factor)) +
  geom_tile(colour = "grey") +
  geom_text(aes(label = round(bayes_factor,2))) +
  scale_fill_gradient2(limits = c(0,5), 
                      midpoint = 1, 
                      low = "#7581B3", 
                      high = "#FA8100") +
  labs(title = "(A) Bayes factor in favour of null", 
       subtitle = "anecdotal to moderate evidence against the null",
       fill = "BF",
       y = "ROPE in semi tones centered on 0\n ",
       x = "\nprior standard deviation") +
  theme_minimal()

```