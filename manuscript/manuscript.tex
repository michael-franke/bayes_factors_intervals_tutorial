\documentclass[
  doc,
  floatsintext,
  longtable,
  nolmodern,
  notxfonts,
  notimes,
  colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue]{apa7}

\usepackage{amsmath}
\usepackage{amssymb}

\geometry{inner=1in, outer=1in}
\fancyhfoffset[LE,RO]{0cm}



\RequirePackage{longtable}
\RequirePackage{threeparttablex}

\makeatletter
\renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
	{0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
	{-.5em}%
	{\normalfont\normalsize\bfseries\typesectitle}}

\renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{0.5em}%
	{0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
	{-\z@\relax}%
	{\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
\makeatother




\usepackage{longtable, booktabs, multirow, multicol, colortbl, hhline, caption, array, float, xpatch}
\usepackage{subcaption}


\renewcommand\thesubfigure{\Alph{subfigure}}
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\textfraction}{0.15}
\renewcommand{\floatpagefraction}{0.7}

\usepackage{tcolorbox}
\tcbuselibrary{listings,theorems, breakable, skins}
\usepackage{fontawesome5}

\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{ACACAC}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582EC}
\definecolor{quarto-callout-important-color-frame}{HTML}{D9534F}
\definecolor{quarto-callout-warning-color-frame}{HTML}{F0AD4E}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02B875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{FD7E14}

%\newlength\Oldarrayrulewidth
%\newlength\Oldtabcolsep


\usepackage{hyperref}



\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}

\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}





\usepackage{newtx}

\defaultfontfeatures{Scale=MatchLowercase}
\defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}





\title{Meaningful results for meaningful hypotheses: A tutorial on
hypothesis testing with Bayes factors using ROPEs}


\shorttitle{Meaningful results for meaningful hypotheses}


\usepackage{etoolbox}









\authorsnames[{1},{2}]{Timo B. Roettger,Michael Franke}







\authorsaffiliations{
{Department of Linguistics \& Scandinavian Studies, University of
Oslo},{Department of Linguistics, University of Tübingen}}




\leftheader{Roettger and Franke}



\abstract{Recent times have seen an increase of interest in Bayesian
inference across the behavioral sciences. However, the process of
testing hypotheses is often conceptually challenging or computationally
costly. This tutorial provides an accessible, non-technical introduction
to a technique that is both conceptually easy to understand and
computationally cheap, and that also covers many common scenarios in the
experimental sciences: Quantifying the relative evidence for a pair of
interval-based hypotheses using Bayes factors through the Savage Dickey
approximation. }

\keywords{statistics, Bayes, Bayes factor, Savage Dickey, hypothesis
testing, ROPE}

\authornote{\par{\addORCIDlink{Timo B. Roettger}{0000-0003-1400-2739}} 
\par{ }
\par{   The authors have no conflict of interest to declare.    }
\par{Correspondence concerning this article should be addressed to Timo
B.
Roettger, Email: \href{mailto:timo.roettger@iln.uio.no}{timo.roettger@iln.uio.no}}
}

\makeatletter
\let\endoldlt\endlongtable
\def\endlongtable{
\hline
\endoldlt
}
\makeatother

\urlstyle{same}



\AtBeginDocument{%
  \setcounter{topnumber}{4}
  \setcounter{bottomnumber}{2}
  \setcounter{totalnumber}{6}
  \renewcommand{\topfraction}{0.95}
  \renewcommand{\bottomfraction}{0.80}
  \renewcommand{\textfraction}{0.07}
  \renewcommand{\floatpagefraction}{0.6}
  \floatplacement{figure}{!tbp}% optional global nudge
  \setlength{\parindent}{5pt}
}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

% From https://tex.stackexchange.com/a/645996/211326
%%% apa7 doesn't want to add appendix section titles in the toc
%%% let's make it do it
\makeatletter
\xpatchcmd{\appendix}
  {\par}
  {\addcontentsline{toc}{section}{\@currentlabelname}\par}
  {}{}
\makeatother

%% Disable longtable counter
%% https://tex.stackexchange.com/a/248395/211326

\usepackage{etoolbox}

\makeatletter
\patchcmd{\LT@caption}
  {\bgroup}
  {\bgroup\global\LTpatch@captiontrue}
  {}{}
\patchcmd{\longtable}
  {\par}
  {\par\global\LTpatch@captionfalse}
  {}{}
\apptocmd{\endlongtable}
  {\ifLTpatch@caption\else\addtocounter{table}{-1}\fi}
  {}{}
\newif\ifLTpatch@caption
\makeatother

\begin{document}

\maketitle



\setcounter{secnumdepth}{3}

\setlength\LTleft{0pt}




\section{Introduction}\label{introduction}

\noindent One of the most common scenarios in experimental research is
to measure one or more (dependent) variables in an experiment with one
or more predictors (independent variables). Usually, if we are testing
hypotheses, we want to statistically test whether the predictors affect
the measured variables. Traditionally, these statistical tests have been
done within the \emph{null hypothesis significance testing} (NHST)
framework.\footnote{Not strictly necessary for this tutorial but, in
  case you need a reminder, the logic of NHST goes something like this:
  we assume ---for the sake of argument--- that a null hypothesis is
  correct, i.e., that there is no effect of a relevant predictor. We
  then ask ourselves how likely different observations would be based on
  that assumption, and use this so-called \emph{sampling distribution}
  to quantify how surprising the observed data is under the assumed null
  hypothesis. If the observed data are very unlikely, we \emph{reject}
  the null hypothesis and conclude that the predictor affects the
  dependent variable.} While extensions of the NHST framework exist, in
its basic form, NHST only allows us to \emph{reject} the null
hypothesis, but not to provide evidence in favor of it. Over the last
decade or so, however, there has been rising interest in statistical
approaches within an alternative inferential framework using
\emph{Bayesian inference}. One of the main reasons for this rising
interest is that Bayesian inference allows to not only quantify evidence
\emph{against} an assumed null hypothesis, but also to yield
quantitative evidence \emph{in favor of} the null hypothesis.

Unfortunately, there are several approaches to hypothesis testing within
the Bayesian framework, and many of them are either conceptually
challenging, computationally (too) costly, or both. For example, there
are good conceptual arguments that support Bayesian hypothesis testing
through \emph{model comparison} using Bayes factors
(\citeproc{ref-KassRaftery1995-Bayes-Factors}{Kass \& Raftery, 1995};
\citeproc{ref-MoreyRomeijn2016-philosophyOfBFs}{Morey et al., 2016};
\citeproc{ref-VandekerckhoveMatzke2013-Model-Compariso}{Vandekerckhove
et al., 2015}), but the computation of Bayes factors can be quite
costly, especially for complex models. Yet, for some of the most common
use cases, there are some simple and computationally cheap approaches to
Bayesian hypothesis testing with Bayes factors that are easy to
understand and implement. One such method is the \emph{Savage-Dickey
density ratio} (\citeproc{ref-DickeyLientz1970-The-Weighted-Li}{Dickey
\& Lientz, 1970};
\citeproc{ref-WagenmakersLodewyckx2010-Bayesian-hypoth}{Wagenmakers et
al., 2010}). While prior work has prominently documented how to use this
method for the case of point-valued null-hypotheses
(\citeproc{ref-WagenmakersLodewyckx2010-Bayesian-hypoth}{Wagenmakers et
al., 2010}), this method can be hard to estimate reliably with posterior
sampling, which is the most prevalent method for approximating Bayesian
computation at the moment. This tutorial therefore focuses on the use of
the Savage-Dickey density ratio for testing hypotheses that are grounded
in \emph{regions of practical equivalence} (ROPEs)
(\citeproc{ref-kruschke_Rejecting_journalarticle_2018}{Kruschke, 2018})
using the so-called \emph{encompassing priors} approach
(\citeproc{ref-KlugkistKato2005-Bayesian-model}{Klugkist et al., 2005};
\citeproc{ref-KlugkistHoijtink2007-The-Bayes-facto}{Klugkist \&
Hoijtink, 2007}; \citeproc{ref-Oh2014-Bayesian-compar}{Oh, 2014};
\citeproc{ref-WetzelsGrasman2010-An-encompassing}{Wetzels et al.,
2010}), which is both conceptually more meaningful and computationally
more robust than point-valued hypothesis testing. While this method does
not seem to be widely known, it is conceptually simple and easy to
apply, e.g., through implementation in the package
\texttt{bayesfactorR}. This tutorial therefore provides an accessible,
non-technical introduction to this method of Bayesian hypothesis
testing, which is easy to understand, computationally cheap and widely
applicable.

\section{Motivation and intended
audience}\label{motivation-and-intended-audience}

\noindent This tutorial provides a very basic introduction to hypothesis
testing with Savage-Dickey density ratios using R (R Core Team, 2025).
We wrote this tutorial with a particular reader in mind. If you have
used R before and if you have a basic understanding of linear regression
and Bayesian inference, this tutorial is for you. We will remain mostly
conceptual to provide you with an accessible tool to approach hypothesis
testing within Bayesian inference. The form of hypothesis testing that
we would like to introduce to you is, however, different from the
traditional null hypothesis significance testing in that it requires
more thinking about the quantitative nature of your data. This is not a
bug but, at least for us, a feature that will allow you to understand
both your data and what you can learn from them better.

If you don't have any experience with regression modeling, you will
probably still be able to follow, but you might also want to consider
doing a crash course. To bring you up to speed, we recommend the
excellent tutorial by Bodo Winter
(\citeproc{ref-winter_Linear_preprint_2013}{2013}) on mixed eﬀects
regression in a non-Bayesian paradigm. To then make the transition to
Bayesian versions of these regression models, we shamelessly suggest our
own tutorial on ``Bayesian Regression for Factorial Designs''
(\citeproc{ref-franke-roettger_Bayesian_preprint_2019}{Franke \&
Roettger, 2019}). In a sense, the present tutorial on hypothesis testing
could be considered the long-awaited sequel (!?) of the series started
by Winter, as all three tutorials use the same data set.

To actively follow this tutorial, you find all code and data in this
repository:
https://github.com/michael-franke/bayes\_factors\_intervals\_tutorial.
You should have R (\citeproc{ref-R_program}{R Core Team, 2025})
installed on your computer (https://www.r-project.org). Unless you
already have a favorite editor for tinkering with R scripts, we
recommend to try out RStudio (https://www.rstudio.com). You will also
need some packages, which you can import with the following code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# package for Bayesian regression modeling}
\FunctionTok{library}\NormalTok{(brms)}

\CommentTok{\# package for BF calculation and plotting}
\FunctionTok{library}\NormalTok{(bayestestR)}
\end{Highlighting}
\end{Shaded}

\section{Data, research questions \&
hypotheses}\label{data-research-questions-hypotheses}

\noindent In this section, we introduce the data set that we will use
throughout this tutorial, the research question that we want to address,
and how to formulate meaningful hypotheses in a way that allows us to
test them with Bayes factors using so-called Regions of Practical
Equivalence (ROPEs), to be introduced below.

\subsection{The data set: Voice pitch in Korean across social
contexts}\label{the-data-set-voice-pitch-in-korean-across-social-contexts}

\noindent This tutorial looks at a data set relevant for investigating
whether voice pitch diﬀers across social contexts in Korean. Korean is a
language in which the social distance between speakers plays a central
role to the way utterances are pronounced. The way Korean speakers talk
depends for example on whether they are in a formal context (e.g.~during
a job interview) or an informal context (e.g.~chatting with a friend
about the holidays). Toe investigate this, our data set contains pitch
measurements of utterances in different social contexts
(\citeproc{ref-winter-grawunder_Phonetic_journalarticle_2012}{Winter \&
Grawunder, 2012}). To load and inspect the data into your R environment,
run the following code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{polite }\OtherTok{\textless{}{-}} 
  
  \CommentTok{\# load data set \& cast strings to factors}
  \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"https://tinyurl.com/4tn26494"}\NormalTok{, }\AttributeTok{col\_types =} \StringTok{"ffffd"}\NormalTok{) }\SpecialCharTok{|\textgreater{}} 
  \CommentTok{\# set factor reference level for factor \textasciigrave{}gender\textasciigrave{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gender =} \FunctionTok{fct\_relevel}\NormalTok{(gender, }\StringTok{"male"}\NormalTok{))}

\FunctionTok{head}\NormalTok{(polite)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 5
  subject gender sentence context  pitch
  <fct>   <fct>  <fct>    <fct>    <dbl>
1 F1      female S1       formal    213.
2 F1      female S1       informal  204.
3 F1      female S2       formal    285.
4 F1      female S2       informal  260.
5 F1      female S3       formal    204.
6 F1      female S3       informal  287.
\end{verbatim}

This data set contains anonymous identifiers for individual speakers
stored in the variable \texttt{subject}. Voice pitch is dependent on
speakers' \texttt{gender}, which we need to take into account as well.
Speakers produced diﬀerent \texttt{sentences}, and the experiment
manipulated whether the sentences were produced in a \texttt{formal} or
an \texttt{informal} social \texttt{context}. Crucially, each row
contains a measurement of pitch in Hz stored in the variable
\texttt{pitch}.

For most analyses of behavioral experiments, researchers are interested
in whether an outcome variable is meaningfully affected by at least one
manipulated variable and if so how the outcome variable is affected by
it. In this case, Winter and Grawunder
(\citeproc{ref-winter-grawunder_Phonetic_journalarticle_2012}{2012})
wanted to test whether voice pitch is meaningfully affected by the
social context of the utterance.

As a first step, we can explore this question visually.
Figure~\ref{fig-descriptive-dataviz} displays the pitch values for all
utterances in the dataset across contexts (semi-transparent points). The
solid points indicate the average pitch values across all sentences and
speakers. Looking at the plot, we can see that voice pitch from
utterances in formal contexts are on average slightly lower than those
in informal contexts: The red distribution is slightly shifted to the
left of the blue distribution by 10-ish Hz for male speakers and 30-ish
Hz for female speakers. In other words, speakers tend to slightly lower
their voice pitch when speaking in a formal context. But there is also a
lot of overlap between the two contexts. Now as Bayesians, we would like
to translate the data into an expression of evidence: Does the data
provide evidence for our research hypotheses?

\begin{figure}[!tbph]

\caption{\label{fig-descriptive-dataviz}Empirical distribution of
speakers' pitch values across contexts and sex}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{manuscript_files/figure-pdf/fig-descriptive-dataviz-1.pdf}}

}

\end{figure}%

\subsection{A Bayesian regression model to address our research
question}\label{a-bayesian-regression-model-to-address-our-research-question}

\noindent Let us build a Bayesian linear model to approach an answer to
this question. Using the package \texttt{brms}
(\citeproc{ref-Burkner2018-Advanced-Bayesi}{Bürkner, 2018}), our first
step is to specify the model formula and check which priors need to be
specified:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# contrast code predictors}
\FunctionTok{contrasts}\NormalTok{(polite}\SpecialCharTok{$}\NormalTok{context) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}
\FunctionTok{contrasts}\NormalTok{(polite}\SpecialCharTok{$}\NormalTok{gender) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}

\CommentTok{\# define linear model formula}
\CommentTok{\# predict pitch by context and gender}
\CommentTok{\# and allow for context to vary between subjects and sentences}
\NormalTok{formula }\OtherTok{\textless{}{-}} \FunctionTok{bf}\NormalTok{(pitch }\SpecialCharTok{\textasciitilde{}}\NormalTok{ context }\SpecialCharTok{+} 
\NormalTok{                      gender }\SpecialCharTok{+} 
\NormalTok{                      (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ context }\SpecialCharTok{|}\NormalTok{ subject) }\SpecialCharTok{+}
\NormalTok{                      (}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ context }\SpecialCharTok{|}\NormalTok{ sentence))}

\CommentTok{\# get information about priors that are set per default for this model}
\CommentTok{\# NB: no prior for \textasciigrave{}context1\textasciigrave{} is set per default (!)}
\FunctionTok{as\_tibble}\NormalTok{(}\FunctionTok{get\_prior}\NormalTok{(formula, polite)) }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{select}\NormalTok{(class, prior) }\SpecialCharTok{|\textgreater{}} \FunctionTok{filter}\NormalTok{(prior }\SpecialCharTok{!=} \StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 2
  class     prior                    
  <chr>     <chr>                    
1 cor       lkj(1)                   
2 Intercept student_t(3, 203.9, 82.7)
3 sd        student_t(3, 0, 82.7)    
4 sigma     student_t(3, 0, 82.7)    
\end{verbatim}

The default priors that \texttt{brms} picks for the Intercept and the
variance parameters are mostly reasonable as they are derived from the
data. They are weakly informative and symmetrical. However the default
choice for our critical parameter \texttt{context1} is to not specify a
prior at all, i.e., to assume a flat (improper) prior, so that it is not
even listed in the table above. Yet, there are good arguments why it
should also receive a weakly informative prior
(\citeproc{ref-gelman-etal_Prior_journalarticle_2017}{Gelman et al.,
2017}), i.e.~the prior assumption about the difference between informal
and formal contexts should be that we don't know, but our best guess is
that it is zero in expectation and equally likely to be more or less
than zero. So we specify a normal distribution centered on zero for this
parameter (and we do the same for gender). Since we used contrast
coding, the prior for \texttt{context1} reflects our prior belief about
the difference between formal and informal contexts. Note that we use
default priors for the other parameters for convenience here, but you
should always critically reflect on all of your priors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define a weakly informative prior for context and gender}
\NormalTok{priors }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{prior}\NormalTok{(}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{20}\NormalTok{), }\AttributeTok{coef =} \StringTok{"context1"}\NormalTok{),}
            \FunctionTok{prior}\NormalTok{(}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{), }\AttributeTok{coef =} \StringTok{"gender1"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now we inspect how the parameter distribution looks like \emph{before}
having seen the data, based on the priors only. This is a useful
exercise to make sure that the priors result in reasonable quantitative
assumptions. We usually do it for all parameters, but here we will focus
only on the critical parameter \texttt{context1}, i.e.~the difference
between formal and informal contexts. Let us also have a look at the
predictions for the prior-only model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# run the prior{-}only model}
\NormalTok{fit\_prior }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(formula, }\AttributeTok{prior =}\NormalTok{ priors, }\AttributeTok{data =}\NormalTok{ polite,}
           \CommentTok{\# sample prior only}
           \AttributeTok{sample\_prior =} \StringTok{"only"}\NormalTok{,}
           \CommentTok{\# common sampling specifications}
           \AttributeTok{seed =} \DecValTok{1234}\NormalTok{, }\AttributeTok{iter =} \DecValTok{8000}
\NormalTok{           )}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!tbp]

\caption{\label{fig-plot-priors}Prior probability of the difference in
pitch between contexts, i.e.~before seeing the data}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{manuscript_files/figure-pdf/fig-plot-priors-1.pdf}}

}

\end{figure}%

Looking at the distribution in Figure~\ref{fig-plot-priors}, the priors
for the effect of context on pitch seems sensible. The most plausible
value is zero. Values that are smaller or larger than zero become less
plausible the further they are away from zero and values being smaller
or larger than zero are equally likely. Good. Before we have seen the
data, our model is somewhat pessimistic about the effect of context on
pitch. Now we can run the full model that integrates the likelihood (our
data) with the priors and visualize the posteriors for the critical
parameter.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# run the model}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(formula, }\AttributeTok{prior =}\NormalTok{ priors, }\AttributeTok{data =}\NormalTok{ polite,}
           \AttributeTok{seed =} \DecValTok{1234}\NormalTok{, }\AttributeTok{iter =} \DecValTok{8000}
\NormalTok{           )}
\end{Highlighting}
\end{Shaded}

\begin{figure}[!tbp]

\caption{\label{fig-plot-posterior}Posterior probability of the effect
of context on pitch, i.e.~after seeing the data}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{manuscript_files/figure-pdf/fig-plot-posterior-1.pdf}}

}

\end{figure}%

Figure~\ref{fig-plot-posterior} shows the prior (red distribution) and
posterior (gold distribution) probability of the effect of context on
pitch. The distribution of posterior samples suggests that the majority
of plausible values after seeing the data are positive, or in other
words, informal contexts elicit larger pitch values. Negative values are
not very plausible under the posterior distribution, but also not
completely implausible. Compared to our prior probability (red
distribution) for which roughly 50\% of posteriors are negative, this
decrease in plausibility of negative values is quite noteworthy already.

What we have done here should be quite familiar. We care about whether
values are positive or negative because we compare our model predictions
to a reference point: the single point value zero. But do we really care
that much for such point hypotheses? Is zero really that special? We
might think so because years of using null hypothesis significance
testing has conditioned us to think that way. But we can also go beyond
point-values if we see reason to do so.

\subsection{Grounding hypotheses in Regions of Practical
Equivalence}\label{grounding-hypotheses-in-regions-of-practical-equivalence}

\noindent Above we claimed that we wanted to test ``whether pitch is
\textbf{meaningfully affected} by the social context of the utterance''.
We snuck the word ``meaningfully'' in there for a reason. But what does
``meaningful'' mean? This is an interesting yet deep questions and
(un)fortunately requires some thinking. What a meaningful difference
really constitutes depends on the context of the data. So let's have a
closer look at our data.

This tutorial deals with speech data. Speech is, in spoken languages at
least, \emph{the} vehicle to transmit linguistic information in order to
communicate with each other. Speech is also very complex and very noisy:
Not everything that can be measured in the acoustic signal matters for a
listener. For example, if something cannot be perceived reliably, it is
at least conceivable that it might play little to no role in
communication. While the speech sciences have a rich research tradition
to estimate what can and what cannot be reliably heard, exact estimation
depends on a lot of moving parts. Approximate thresholds of what can be
reliably heard are often referred to as \emph{Just Noticeable
Differences} (JNDs). This terminology has been argued to be dangerously
misleading (\citeproc{ref-SanfordHalberda2023-A-Shared-Intuit}{Sanford
\& Halberda, 2023}) as it implies a hard and absolute threshold of
perceptibility, while in fact many researchers work with a more lenient
and more practical conceptualization of a threshold at which the
probability that our perceptual system registers a stimulus or a
stimulus difference is below a given probability threshold. By
convention, the JND is often defined as the point where listener
accuracy exceeds the arbitrary threshold of 75\%. When we say ``just
noticeable difference'' in the following we mean that latter
probabilistic notion, as we would like to use the idea of regions at
which the perceptual system is unlikely to reliably register a stimulus
difference as a means of justifying a Region of Practical Equivalence
(ROPE). For example, while classic work by Klatt
(\citeproc{ref-klatt1973discrimination}{1973}) suggest JNDs ranging from
0.3 to 4 Hz, more modern treatments such as Turner et al.
(\citeproc{ref-turner2019perception}{2019}) report on JNDs between 17
and 25 Hz for non-speech stimuli and between 35 and 40 Hz for speech
stimuli. While these studies are hard to compare, their effect
magnitudes are grounded in a comparable probability threshold (75\%
accuracy). Thus, they give us at least an idea about the rough order of
magnitude for JND values to work with when it comes to speech data like
the data set at hand.

Based on these considerations, we could interpret the original
hypothesis the following way: If a pitch difference is below the JND, it
is not (practically) meaningful. So, instead of testing against a
point-valued hypothesis, we can test against a range of parameter values
that are equivalent to the null value for practical purposes. In our
case, let us begin with a JND value that is somewhat conservative in
relation to Klatt (\citeproc{ref-klatt1973discrimination}{1973}) and
somewhat liberal in relation to Turner et al.
(\citeproc{ref-turner2019perception}{2019}): We assume that pitch values
between \texttt{-10} and \texttt{10} are negligible. Bear with us, we
will later revisit this assumption. Said differently, in order to be
convinced that a difference in pitch is meaningful, it should be
reliably greater than 20 Hz. Such ranges are sometimes called
\emph{Regions of Practical Equivalence} (ROPEs), range of equivalence,
equivalence margin, smallest effect size of interest, or good-enough
belt (see
\citeproc{ref-kruschke_Rejecting_journalarticle_2018}{Kruschke, 2018}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# define our ROPE}
\NormalTok{rope }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

With a ROPE being defined, we can now test our hypothesis ``whether
pitch is \textbf{meaningfully affected} by the social context of the
utterance'' using Bayes factors.

\section{Testing hypotheses using Bayes
factors}\label{testing-hypotheses-using-bayes-factors}

\subsection{What are Bayes factors?}\label{what-are-bayes-factors}

\noindent We often consider two hypotheses \(H_0\) and \(H_1\), and want
to know which of these is correct. We do so by looking at some observed
data \(D\). As Bayesians, the first most obvious thing to look at is how
likely each hypothesis is after seeing the data, i.e., something like
\(P(H_0 \mid D)\) and \(P(H_1 \mid D)\). Now, it turns out that these
\emph{posterior probabilities of hypotheses} are problematic, because
they depend on the prior probabilities of the hypotheses \(P(H_0)\) and
\(P(H_1)\), which are often hard to justify. To see this, imagine that
the hypotheses to compare are polarizing issues like contrasting
Darwinian evolutionary theory and a dull form of creationism, referred
to here as \emph{arbitrary design}. Proponents of either view would have
a hard time agreeing on priors for these hypotheses, but may find it
much easier to agree on whether a given observation \(D\) is more likely
under the assumption that one of the two hypotheses is correct, rather
than the other. Therefore, Bayes factors are defined as the
\emph{likelihood ratio} of the data given each hypothesis:

\[
\text{Bayes factor in favor of hypothesis 1 over hypothesis 0} \ \  \colon\!= \ \ \frac{P(D \mid H_1)}{P(D \mid H_0)}
\]

To see how this is a more objective and actually quite intuitive measure
of observational evidence in scientific reasoning, consider the case of
Darwinian evolution (\(H_1\)) versus arbitrary design (\(H_0\)) again.
Let's assume that the observed data \(D\) consist of (i) measurements of
the beak shapes of finches on two different islands, and (ii)
information about the food sources available on these islands. Let's
assume for simplicity that on island A the predominant food source are
insects found deep in wood or earth, and that on island B it is insects
with hard shells living on the surface. We also observe that finches on
island A have long and narrow beaks, while finches on island B have
short and thick beaks. (This here is a crude simplification of an actual
case that led Darwin to formulate his theory, but bear with us for the
sake of the example.) What is a better explanation of data \(D\),
evolutionary selection or arbitrary design? To begin with, let's notice
that \(D\) is \emph{not} ruled out by either hypothesis. But the
probability of observing \(D\) is higher under Darwinian evolution
(\(H_1\)) than under arbitrary design (\(H_0\)). This is because, before
seeing the data, a proponent of evoluationary theory \(H_1\), if asked
to make a prediction about beak shapes under the given food sources,
would have considered it \emph{more} likely that beaks are adapted to
their function of exploiting the dominant food source, so making the
actually observed data \(D\) more likely \emph{ex ante} than at least
some other possible observations. In contrast, a proponent of arbitrary
design \(H_0\) would not have had any reason to expect that beak shapes
are adapted to food sources, and would like to be able to rationalize
\emph{ex post} also any apparent violation of this expectation as the
inscrutable way of the arbitrary designer. To the extent that there are
many alternative observations which arbitrary design would consider
reasonably likely \emph{ex ante} but evoluationary selection would rule
out (or deem very unlikely), the probability of the observed data is
much higher under Darwinian evolution than under arbitrary design, so
that \(P(D \mid H_1) > P(D \mid H_0)\), irrespective of what we
initially believed is the more plausible hypothesis. This is what
corroborates the intuition that the observation \(D\) is an argument in
favor of \(H_1\) over \(H_0\). This intuition is exactly what the Bayes
factor quantifies.

Concretely, a Bayes factor of 1 corresponds to the case of
\(P(D \mid H_1) = P(D \mid H_0)\), i.e., the data is equally likely
under both hypotheses, so the data does not provide any evidence for or
against either hypothesis. Any Bayes factor larger than 1 indicates that
the data is more likely under \(H_1\) than under \(H_0\), and the larger
the Bayes factor, the stronger the evidence in favor of \(H_1\).
Conversely, any Bayes factor smaller than 1 indicates that the data is
more likely under \(H_0\) than under \(H_1\). Notice that the Bayes
factor is symmetric in the sense that a Bayes factor of 3 in favor of
\(H_1\) over \(H_0\) corresponds to a Bayes factor of 1/3 in favor of
\(H_0\) over \(H_1\). There are various conventions for interpreting the
strength of evidence of Bayes factors, such as to consider Bayes factors
smaller than 3 as ``\emph{anecdotal evidence}''; Bayes factors bigger
than 3 as ``\emph{moderate evidence}''; and Bayes factors bigger than 10
as ``\emph{strong evidence}''.

One way to interpret Bayes factors in absolute terms is this: A Bayes
factor of \(n\) in favor of \(H_1\) over \(H_0\) means that after seeing
the data, a rational researcher who initially thought both hypotheses
were equally likely would consider \(H_1\) to be \(n\) times more likely
than \(H_0\) after observing \(D\).

\subsection{Bayes factors for statistical
models}\label{bayes-factors-for-statistical-models}

\noindent After motivating Bayes factors in general, let's have a look
at the definition of Bayes factors in the context of statistical models
in this section. What follows in this section is a bit more technical,
so you can skip ahead without missing out too much information for
applying these methods.

In the context of statistical models, we can use Bayes factors to
compare two statistical models \(M_0\) and \(M_1\) that instantiate two
competing hypotheses (or assumptions) \(H_0\) and \(H_1\). A Bayesian
statistical model \(M\) consists of:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  a \emph{likelihood function} \(P(D \mid \theta, M)\) that specifies
  how likely the observed data \(D\) is given the model \(M\) and the
  model's parameters \(\theta\), and
\item
  a \emph{prior distribution} \(P(\theta \mid M)\) that specifies how
  likely different parameter values are before seeing the data.
\end{enumerate}

The probability of some observed data \(P(D \mid M)\) under a model
\(M\) is then obtained by integrating over all possible parameter values
\(\theta\):

\[
P(D \mid M) = \int P(D \mid \theta, M) \ \  P(\theta \mid M) \ \text{d} \theta
\]

This is called the \emph{marginal likelihood} of the data under the
model \(M\). We can think of this quantity as obtained from sampling
parameter values from the prior and then sampling, for each of the
sampled parameter values, a potential data observation. (Notice that
this is the \emph{prior predictive data distribution} of the model.)

Putting things together, the resulting definition for Bayes factors in
statistical models is:

\[
\text{Bayes factor in favor of model 1 over model 0} \ \  \colon\!= \ \ \frac{P(D \mid M_1)}{P(D \mid M_0)} = \frac{\int P(D \mid \theta, M_1) \ \  P(\theta \mid M_1) d\theta}{\int P(D \mid \theta, M_0) \ \  P(\theta \mid M_0) d\theta}
\]

\subsection{Bayes factor for point-valued hypotheses (the Savage-Dickey
method)}\label{bayes-factor-for-point-valued-hypotheses-the-savage-dickey-method}

\noindent While Bayes factors are a very intuitive and useful measure of
evidence, they are often hard to compute. There are various
approximation methods, such as bridge sampling
(\citeproc{ref-GronauSarafoglou2017-A-tutorial-on-b}{Gronau et al.,
2017}), which can be used for any arbitrary pair of models, but these
can still be computationally costly and sometimes hard to implement.
However, for the special case of \emph{nested models}, there is a simple
and computationally cheap approximation method called the
\emph{Savage-Dickey density ratio}
(\citeproc{ref-DickeyLientz1970-The-Weighted-Li}{Dickey \& Lientz,
1970};
\citeproc{ref-WagenmakersLodewyckx2010-Bayesian-hypoth}{Wagenmakers et
al., 2010}).

What are nested models? Intuitively speaking, model \(M_0\) is nested in
model \(M_1\) if \(M_0\) can be obtained from \(M_1\) by setting one or
more parameters to a specific value. (More precisely, by conditioning on
a specific value of one or more parameters.) For example, take the
regression model \(M_1\) for the Korean speech data we introduced at the
beginning of this tutorial. We suggested a normal distribution on the
\texttt{context} coefficient as a prior. A model \(M_0\) nested under it
would be one that is exactly like \(M_1\) except that \(M_0\)'s prior
for the \texttt{context} coefficient allows only one value, e.g., that
the slope coefficient is equal to zero. That model \(M_0\) would then
correspond to the (standard, point-valued) null hypothesis that there is
no effect of \texttt{context} on \texttt{pitch}. This process might
sound familiar to people who have generated p-values for linear mixed
effects models before. One way to check if a predictor significantly
affects a dependent variable is by comparing a full model to a null
model. The null model is the full model minus the critical predictor,
which is clamped to a specific value, so to speak.

So, suppose that \(M_0\) is nested in \(M_1\) by fixing a critical
parameter \(\theta^*\) to a specific value \(x\). Then, the
Savage-Dickey density ratio states that the Bayes factor in favor of
\(M_1\) over \(M_0\) can be computed as the ratio of the prior and
posterior density of \(\theta^*=x\) from \(M_1\)'s point of view: \[
\text{Bayes factor in favor of model 0 over model 1} \ \  = \ \  \frac{P(\theta^*=x \mid D, M_1)}{P(\theta^*=x \mid M_1)}
\]

Let's unpack this. First of all, this seemingly magical result is
actually not that magical, but follows directly from the definition of
Bayes factors and Bayes' theorem. Don't worry. We won't bother you with
the derivation here. But that means that in practice we do not have to
calculate or approximate any integrals at all, but we can simply look at
the more complex model \(M_1\) and its prior and posterior parameter
distributions, like we routinely do with \texttt{brms}, for example.
Look at the formula above: we would only need to run one model, \(M_1\),
and then look at the prior and posterior density of the critical
parameter \(\theta^*\) at the point value \(x\). The prior us usually
easily determined because it is in our hands to specify it. The
posterior can by estimated from the samples that are returned by
software like \texttt{brms} \ldots{}

\ldots{} well, at least in principle. One problem here is that
estimating \(P(\theta^*=x \mid D, M_1)\) from posterior samples is
fickle. We can do it with some mathematical methods, but we may need a
lot of samples and do some post-processing (e.g., using splines). But
one technical wrinkle is that posterior samples are less reliable for
estimating densities at specific points, but are usually more reliable
for estimating probabilities over wide-enough intervals of
values.\footnote{The problem is one of a class of so-called
  \textbf{vanishing measures problems}. The probability of a point value
  is a probability \emph{density}. Markov Chain Monte Carlo (MCMC)
  methods, which are used by \texttt{brms} and many other Bayesian
  software packages, generate samples from the posterior distribution.
  It is extremely unlikely that you will ever get a sample that is
  exactly equal to the point value \(x\). So you would need to estimate
  something like the probabilities of a very small interval around
  \(x\), and put that in relation to similarly small intervals for all
  other possible values of \(\theta^*\) to get a reliable estimate of
  the density at \(x\).} Moreover, point-valued hypotheses may often not
be that interesting or meaningful in practice anyway, as argued above.
Fortunately, there is a generalization of the Savage-Dickey density
ratio that works for ranges of values, too!

\subsection{Bayes factors for interval-based hypotheses (like
ROPEs)}\label{bayes-factors-for-interval-based-hypotheses-like-ropes}

\noindent The Savage-Dickey density ratio can be generalized to the case
where the null hypothesis \(H_0\) is not a point-valued hypothesis, but
a hypothesis that the critical parameter \(\theta^*\) lies in some
interval \(I_0\), such as our ROPE from above. There are several
different ways to define the alternative hypothesis \(H_1\) in this
case, but the most common one is to define it as the complement of
\(H_0\), i.e., that \(\theta^*\) lies in the interval that contains all
values that are not in \(I_0\), so that:

\[
H_0 = \theta^* \in I_0 \ \ \ \ \ \ \ \  H_1 = \theta^* \not \in I_0
\]

An efficient way of computing Bayes factors for such a setting is to use
the so-called \emph{encompassing priors approach}
(\citeproc{ref-KlugkistKato2005-Bayesian-model}{Klugkist et al., 2005};
\citeproc{ref-KlugkistHoijtink2007-The-Bayes-facto}{Klugkist \&
Hoijtink, 2007}; \citeproc{ref-Oh2014-Bayesian-compar}{Oh, 2014};
\citeproc{ref-WetzelsGrasman2010-An-encompassing}{Wetzels et al.,
2010}). According to this approach, we consider an \emph{encompassing
model} \(M_e\) that contains both the null and the alternative
hypothesis as special cases. Concretely, the encompassing model \(M_e\)
could be just a regression model like the model we used above for the
Korean speech data, with a prior distribution on the critical parameter
\(\theta^*\), such as the normal distribution on the slope coefficient
for \texttt{context}. The null model \(M_0\) would then be the nested
model that is obtained from \(M_e\) by conditioning on
\(\theta^* \in I_0\), and the alternative model \(M_1\) would be the
nested model that is obtained from \(M_e\) by conditioning on
\(\theta^* \not \in I_0\). An alternative intuition can be gained by
visualizing this principle. In Figure~\ref{fig-savage-dickey_TR}, blue
parts of the sampled distributions fall within the ROPE representing the
null model \(M_0\), grey parts fall outside the ROPE representing the
alternative model \(M_1\). We get a null and an alternative model for
both the model before observing the data, and after observing the data.

Based on this setup, the Bayes factor in favor of \(M_0\) over \(M_1\)
can be computed as the ratio of the posterior and prior odds of
\(\theta^*\) being in \(I_0\) (blue parts of the distributions) versus
being in \(I_1\) (grey parts), where \(I_1\) is the complement of
\(I_0\):

\[
BF_{01} = \frac{P(\theta \in I_{0} \mid D, M_{e})}{P(\theta \in I_{1} \mid D, M_{e})} \ \frac{P(\theta \in I_{1} \mid  M_{e})}{P(\theta \in I_{0} \mid M_{e})}
\]

\begin{figure}[!tbp]

\caption{\label{fig-savage-dickey_TR}}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{manuscript_files/figure-pdf/fig-savage-dickey_TR-1.pdf}}

}

\end{figure}%

\subsection{Manually calculating the Bayes factor for our ROPE
hypothesis}\label{manually-calculating-the-bayes-factor-for-our-rope-hypothesis}

\noindent To calculate the Bayes factor for our ROPE hypothesis, we can
use the formula above using samples from the prior and the posterior
based on our encompassing model. For the case of the Korean speech data,
we already obtained prior samples above in the \texttt{fit\_prior}
model, and posterior samples in the \texttt{fit} model. So, we can use
these to extract the proportion of samples that fall inside and outside
of our ROPE and do the calculations by hand. Let's do this first.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_ROPE }\OtherTok{\textless{}{-}}\NormalTok{ fit\_prior }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{spread\_draws}\NormalTok{(b\_context1) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{prior\_ROPE =} \FunctionTok{mean}\NormalTok{(b\_context1 }\SpecialCharTok{\textgreater{}=}\NormalTok{ rope[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\&}\NormalTok{ b\_context1 }\SpecialCharTok{\textless{}=}\NormalTok{ rope[}\DecValTok{2}\NormalTok{])) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{()}

\NormalTok{post\_ROPE }\OtherTok{\textless{}{-}}\NormalTok{ fit }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{spread\_draws}\NormalTok{(b\_context1) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{post\_ROPE =} \FunctionTok{mean}\NormalTok{(b\_context1 }\SpecialCharTok{\textgreater{}=}\NormalTok{ rope[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\&}\NormalTok{ b\_context1 }\SpecialCharTok{\textless{}=}\NormalTok{ rope[}\DecValTok{2}\NormalTok{])) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Using these numbers, we can now calculate the Bayes factor in favor of
the null hypothesis that the effect of \texttt{context} on
\texttt{pitch} is in the ROPE versus the alternative hypothesis that it
is outside of the ROPE:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{BF\_favoring\_Null }\OtherTok{\textless{}{-}}\NormalTok{ (post\_ROPE }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ post\_ROPE)) }\SpecialCharTok{/}
\NormalTok{                    (prior\_ROPE }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ prior\_ROPE))}
\NormalTok{BF\_favoring\_Null}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.396978
\end{verbatim}

The Bayes factor in favor of the alternative hypothesis is simply the
inverse of this number:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{BF\_favoring\_Alt }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ BF\_favoring\_Null}
\NormalTok{BF\_favoring\_Alt}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.519031
\end{verbatim}

With a Bayes factor of around 2.52, the data does not provide noteworthy
evidence in favor of the alternative hypothesis that the effect of
\texttt{context} on \texttt{pitch} is outside of the ROPE.

In Figure~\ref{fig-savage-dickey_TR}, the Bayes factor is the amount of
change between (i) the ratio of samples \emph{within} and \emph{outside}
the ROPE in the prior, and (ii) the same quantity for the posterior. So,
to see evidence in favor of the null hypothesis (the ROPE), we would
want to see the ratio of points shift in favor of the points
\emph{inside} of the ROPE as we go from prior to posterior. In the plot
above, this does not seem to be the case. Rather, we see a small shift
that \emph{more} probability mass is located \emph{outside} the ROPE for
the posterior distribution as opposed to inside of it, as compared to
the prior. This is why, at least in direction, the BF tells us to favor
the alternative hypothesis. However, the shift is not so very
pronounced, so that we would not speak of noteworthy evidence in favor
of the alternative hypothesis, let alone strong or decisive evidence.

\subsection{\texorpdfstring{Calculating ROPE-ed Bayes factor with the
\texttt{bayesfactorR}
package}{Calculating ROPE-ed Bayes factor with the bayesfactorR package}}\label{calculating-rope-ed-bayes-factor-with-the-bayesfactorr-package}

\noindent Instead of doing these calculations by hand, we can more
conveniently calculate the Savage Dickey ratio with the
\texttt{bayesfactor\_rope()} function from the \texttt{bayestestR}
package (\citeproc{ref-MakowskiBen-Shachar2019-bayestestR}{Makowski et
al., 2019}). The function takes as input the posterior and prior fit
objects (you can also only provide the posterior fit, in which case the
function will sample from the prior for you). The function then computes
the ratio for the specified rope for the specified parameter. Notice
that the method implemented in this package is slightly different from
the naive one we used above, in that it uses a method that provides more
stable and precise estimates for smaller sets of samples. (The package
actually uses logsplines to estimate the densities of each sample, which
is a more robust method than the naive one we used above.)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{BF\_1 }\OtherTok{\textless{}{-}} \FunctionTok{bayesfactor\_rope}\NormalTok{(}\AttributeTok{posterior =}\NormalTok{ fit, }
                         \AttributeTok{prior =}\NormalTok{ fit\_prior,}
                         \AttributeTok{null =}\NormalTok{ rope, }
                         \AttributeTok{parameter =} \StringTok{"b\_context1"}\NormalTok{)}
\NormalTok{BF\_1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Bayes Factor (Null-Interval)

Parameter |   BF
----------------
context1  | 2.46

* Evidence Against The Null: [-10.000, 10.000]
\end{verbatim}

We obtain (almost) the same result in this way: the Bayes factor in
favor of the alternative hypothesis for the given ROPE is around 2.46.

\subsection{Sensitivity analysis for different priors and
ROPEs}\label{sensitivity-analysis-for-different-priors-and-ropes}

\noindent Now as you probably have guessed already, all these
probabilities are very much dependent on the priors of the model, so it
is important to evaluate the robustness of our Bayes factor-based
interpretation across a range of sensible priors. And as long as we are
not a 100\% sure about what a meaningful difference is, we might as well
explore the robustness of the Bayes factor across different ROPEs,
i.e.~in our case different JNDs. We won't bore you with the code for
that process, but you can follow it along in our scripts. Let us explore
the following ROPE intervals as informed by the two studies cited above
on pitch perception: we test a range of ROPE intervals from 0.3 Hz to 40
Hz. We also assume the following five prior values for the standard
deviation of the critical parameter (centered on zero): 10, 15, 20, 25,
30. These are all sensible prior widths assuming that medium to strong
pitch effects in either direction are plausible.

\begin{figure}[!tbp]

\caption{\label{fig-sensitivity_plot}Bayes factors for a range of priors
and a range of ROPEs}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{manuscript_files/figure-pdf/fig-sensitivity_plot-1.pdf}}

}

\end{figure}%

The combination of Bayes factors is visualized in
Figure~\ref{fig-sensitivity_plot}. Orange cells indicate evidence for
the alternative. Green cells indicate evidence for the null. It becomes
clear that the conclusions we can draw from our data are rather
dependent on the choices we made along the way.

By comparing the Bayes factors along the y-axis, we can see that they
are heavily dependent on the chosen ROPE. We here chose (theoretically
speaking) a quite large range of ROPEs, all of which are informed by
psychoacoustic studies of what pitch differences can be reliably heard
and thus likely are meaningful for communication. In light of this range
of possible definitions of what constitutes meaningful differences, our
data do not seem very robust, as illustrated by the shift from orange to
green. Even the smallest ROPE intervals provide only anecdotal to
moderate evidence for the alternative. And the most conservative ROPEs,
following Turner et al. (\citeproc{ref-turner2019perception}{2019}),
leads to moderate to very strong evidence against the alternative
hypothesis.

Additionally, when comparing the Bayes factors along the x-axis, we can
see that they are comparatively consistent for different standard
deviations of the critical prior. However, we can also see that the
Bayes factors decrease with the width of the priors (from left to
right). This is not surprising and a known phenomenon, often discussed
under the Jeffreys-Lindley paradox
(\citeproc{ref-lindley_Statistical_journalarticle_1957}{Lindley, 1957}):
The more diffuse the priors are (i.e.~wider priors), the larger is the
probability that a specific parameter values is not compatible with the
data.

Combined, we can see that the larger the ROPE and the wider the priors,
the more likely becomes the null hypothesis. In an ideal world, the
evidence provided by the data should be robust across these choices.
However, this exploration of our inference is a fantastic opportunity to
assess the boundaries of our conclusions. In this case, the original
conclusions of the educational materials from Winter
(\citeproc{ref-winter_Linear_preprint_2013}{2013}) was based on the null
hypothesis significance testing framework, traditionally testing the
compatibility of the data with a point-null hypothesis. Given his
framework, it is reasonable to conclude that in formal speech, Korean
speakers lower their average fundamental frequency. However, thinking
more deeply about the theoretical consequences of differences in pitch,
it might be less clear that these differences are truly meaningful.

\section{How to write this inferential procedure
up?}\label{how-to-write-this-inferential-procedure-up}

\noindent Here is a possible way to write up our analysis, following
Kruschke's catalog of best practices
(\citeproc{ref-Kruschke2021-Bayesian-Analys}{Kruschke, 2021}). We first
have to describe our model structure, including the priors of all
parameters, and then the inferential procedure combining ROPEs with
Bayes factor.

\subsection{Model structure}\label{model-structure}

\noindent The data were modeled using a hierarchical linear model
predicting the continous variable pitch (in Hz) by both the categorical
predictor gender (male vs. female, contrast-coded) and social context
(informal vs. formal, contrast-coded) and the maximal random-effects
structure justified by the study's design (Barr et al. 2013), including
by-subject random slopes (n = 7), and by-sentence random slopes (n = 6)
for social context. Parameter estimation and inference is performed
within the Bayesian framework. The model was fit using \texttt{brms}
(\citeproc{ref-Burkner2018-Advanced-Bayesi}{Bürkner, 2018}) in R
(\citeproc{ref-R_program}{R Core Team, 2025}). We used regularizing,
weakly informative priors for the models (Gelman, Simpson, \& Betancourt
2017). Concretely, we used a Student's \emph{t} distribution for the
prior for the intercept (df = 3, mean = 203.9, df = 82.7), corresponding
to the grand mean of the empirical data, a Student's \emph{t}
distribution for the prior for all random effect variance components as
well as residual variance (df = 3, mean = 0, df = 82.7), and a
Lewandowski-Kurowicka-Joe distribution (LKJ, shape = 1) for all
correlational parameters. These priors were default priors, estimated
from the data by brms. We specified a reasonable weakly informative
prior for the predictor gender (normal, mean = 0, sd = 50) and specified
a range of reasonable weakly informative priors for the predictor of
interest: social context (normal, mean = 0, sd = {[}10,15,20,25,30{]}).

We fit this model with four chains of Hamiltonian Monte Carlo sampling
for the estimation of the joint posterior distribution using the No
U-Turn Sampler as implemented in Stan
(\citeproc{ref-carpenter2017stan}{Carpenter et al., 2017}), and 8000
iterations (of which 4000 for warm-up) per chain, distributed across
four processing cores and two threads in within-chain parallelization.

\subsection{Inferential assessment via Bayes factor and
ROPEs}\label{inferential-assessment-via-bayes-factor-and-ropes}

\noindent Using the Bayesian framework, we aim to quantitatively
evaluate the evidence for a perceptually meaningful effect of social
context on pitch values based on our data against the background of our
model and chosen priors. We will combine two statistical concepts to
make this evaluation: First, we define a region of practical equivalence
(ROPE) that will represent a reasonable range of pitch value around zero
that we consider to be not meaningful
(\citeproc{ref-kruschke_Rejecting_journalarticle_2018}{Kruschke, 2018}).
In our case, the ROPE is perceptually defined by studies on just
noticeable differences in pitch perception
(\citeproc{ref-klatt1973discrimination}{Klatt, 1973};
\citeproc{ref-turner2019perception}{Turner et al., 2019}).

Subsequently, we calculate the Savage-Dickey density ratio
(\citeproc{ref-DickeyLientz1970-The-Weighted-Li}{Dickey \& Lientz,
1970};
\citeproc{ref-WagenmakersLodewyckx2010-Bayesian-hypoth}{Wagenmakers et
al., 2010}), i.e., we relate the amount of evidence (the proportion of
posterior samples) within the ROPE for the model based on the priors
only (i.e., before seeing the data) to the amount of evidence within the
ROPE for the model based on both priors and likelihood (i.e., after
seeing the data) (e.g.
\citeproc{ref-WetzelsGrasman2010-An-encompassing}{Wetzels et al.,
2010}). The Savage-Dickey method lets us assess evidence for and against
a null hypothesis using Bayes factor (BF), since we are dealing with
nested models. Since BFs can depend on both the defined ROPE and the
priors of the model, we assessed the sensitivity of the results through
calculating BFs for a range of (sensible) ROPE values and a range of
(sensible) priors. We assumed the ROPE intervals centered on zero from
0.3 Hz to 40 Hz. We assumed the following five prior values for the
width of the context parameter (centered on zero): 10 Hz, 15 Hz, 20 Hz,
25 Hz, and 30 Hz. These are all sensible prior choices assuming
reasonable pitch differences in either direction.

\section{Some words of encouragement}\label{some-words-of-encouragement}

\noindent Bayesian inference in general and this form of hypothesis
testing in particular require much more thinking than we might be used
to. We believe this is a good thing. Many voices have criticized the
lack of engagement that we behavioral scientists invest into thinking
how our theoretical ideas connect to concrete predictions in the
quantitative systems under investigation
(\citeproc{ref-coretta2023multidimensional}{Coretta et al., 2023};
\citeproc{ref-scheel2022most}{Scheel, 2022};
\citeproc{ref-woensdregt2024lessons}{Woensdregt et al., 2024}). The
presented form of hypothesis testing is easy to understand, but does
require to think deeply about prior quantitative assumptions as well as
what it means for observations to be meaningfully different. That is
neither trivial nor easy. But we would like to encourage everybody to
engage in exactly this thinking to better understand the relevant data
in front of us and how it might link to our understanding of cognition
and behavior.

\section{Other Resources}\label{other-resources}

\noindent  There are many fantastic resources out there to help you
learn about the wonderful world of statistics in general and Bayesian
inference in particular. Here are a few recommendations. A very
accessible introduction to linear models in R, using a non-Bayesian
frequentist approach, is (\citeproc{ref-winter2019statistics}{Winter,
2019}). A good and gentle general first introduction to Bayesian
statistics is (\citeproc{ref-KruschkeTextbook}{Kruschke, 2015}). Another
accessible, but slightly more technical introduction is
(\citeproc{ref-Lambert2018-A-Students-Guid}{Lambert, 2018}). A fairly
technical but very comprehensive introduction to Bayesian statistics is
(\citeproc{ref-GelmanCarlin2014-Bayesian-Data-A}{Gelman et al., 2014}).
If you already have some background in statistics, a great resource is
(\citeproc{ref-McElreath2016-Statistical-Ret}{McElreath, 2016/2020}).

\section{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-Burkner2018-Advanced-Bayesi}
Bürkner, P.-C. (2018). {Advanced Bayesian Multilevel Modeling with the R
Package brms}. \emph{{The R Journal}}, \emph{10}(1), 395--411.
\url{https://doi.org/10.32614/RJ-2018-017}

\bibitem[\citeproctext]{ref-carpenter2017stan}
Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B.,
Betancourt, M., Brubaker, M., Guo, J., Li, P., \& Riddell, A. (2017).
Stan: A probabilistic programming language. \emph{Journal of Statistical
Software}, \emph{76}, 1--32.

\bibitem[\citeproctext]{ref-coretta2023multidimensional}
Coretta, S., Casillas, J. V., Roessig, S., Franke, M., Ahn, B.,
Al-Hoorie, A. H., Al-Tamimi, J., Alotaibi, N. E., AlShakhori, M. K.,
Altmiller, R. M., et al. (2023). Multidimensional signals and analytic
flexibility: Estimating degrees of freedom in human-speech analyses.
\emph{Advances in Methods and Practices in Psychological Science},
\emph{6}(3), 25152459231162567.

\bibitem[\citeproctext]{ref-DickeyLientz1970-The-Weighted-Li}
Dickey, J. M., \& Lientz, B. P. (1970). The weighted likelihood ratio,
sharp hypotheses about chances, the order of a {M}arkov chain. \emph{The
Annals of Mathematical Statistics}, \emph{41}(1), 214--226.

\bibitem[\citeproctext]{ref-franke-roettger_Bayesian_preprint_2019}
Franke, M., \& Roettger, T. (2019). \emph{Bayesian regression modeling
(for factorial designs): {A} tutorial}. OSF.
\url{https://doi.org/10.31234/osf.io/cdxv3}

\bibitem[\citeproctext]{ref-GelmanCarlin2014-Bayesian-Data-A}
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., \&
Rubin, D. B. (2014). \emph{Bayesian data analysis} (3rd edition).
Chapman; Hall.

\bibitem[\citeproctext]{ref-gelman-etal_Prior_journalarticle_2017}
Gelman, A., Simpson, D., \& Betancourt, M. (2017). The {Prior Can Often
Only Be Understood} in the {Context} of the {Likelihood}.
\emph{Entropy}, \emph{19}(10), 555.
\url{https://doi.org/10.3390/e19100555}

\bibitem[\citeproctext]{ref-GronauSarafoglou2017-A-tutorial-on-b}
Gronau, Q. F., Sarafoglou, A., Matzke, D., Ly, A., Boehm, U., Marsman,
M., Leslie, D. S., Forster, J. J., Wagenmakers, E.-J., \& Steingroever,
H. (2017). A tutorial on bridge sampling. \emph{Journal of Mathematical
Psychology}, \emph{81}, 80--97.
\url{https://doi.org/doi.org/10.1016/j.jmp.2017.09.005}

\bibitem[\citeproctext]{ref-KassRaftery1995-Bayes-Factors}
Kass, R. E., \& Raftery, A. E. (1995). Bayes factors. \emph{Journal of
the American Statistical Association}, \emph{90}(430), 773--795.

\bibitem[\citeproctext]{ref-klatt1973discrimination}
Klatt, D. H. (1973). Discrimination of fundamental frequency contours in
synthetic speech: Implications for models of pitch perception. \emph{The
Journal of the Acoustical Society of America}, \emph{53}(1), 8--16.

\bibitem[\citeproctext]{ref-KlugkistHoijtink2007-The-Bayes-facto}
Klugkist, I., \& Hoijtink, H. (2007). The bayes factor for inequality
and about equality constrained models. \emph{Computational Statistics
and Data Analysis}, \emph{51}(12), 6367--6379.
\url{https://doi.org/10.1016/j.csda.2007.01.024}

\bibitem[\citeproctext]{ref-KlugkistKato2005-Bayesian-model}
Klugkist, I., Kato, B., \& Hoijtink, H. (2005). Bayesian model selection
using encompassing priors. \emph{Statistica Neelandica}, \emph{59}(1),
57--69.

\bibitem[\citeproctext]{ref-KruschkeTextbook}
Kruschke, J. K. (2015). \emph{Doing {B}ayesian data analysis} (2nd
edition). Academic Press.

\bibitem[\citeproctext]{ref-kruschke_Rejecting_journalarticle_2018}
Kruschke, J. K. (2018). Rejecting or {Accepting Parameter Values} in
{Bayesian Estimation}. \emph{Advances in Methods and Practices in
Psychological Science}, \emph{1}(2), 270--280.
\url{https://doi.org/10.1177/2515245918771304}

\bibitem[\citeproctext]{ref-Kruschke2021-Bayesian-Analys}
Kruschke, J. K. (2021). Bayesian analysis reporting guidelines.
\emph{Nature Human Behaviour}, \emph{5}(10), 1282--1291.
\url{https://doi.org/10.1038/s41562-021-01177-7}

\bibitem[\citeproctext]{ref-Lambert2018-A-Students-Guid}
Lambert, B. (2018). \emph{A student's guide to bayesian statistics}.
Sage Publications.

\bibitem[\citeproctext]{ref-lindley_Statistical_journalarticle_1957}
Lindley, D. V. (1957). A {Statistical Paradox}. \emph{Biometrika},
\emph{44}(1/2), 187--192. \url{https://doi.org/10.2307/2333251}

\bibitem[\citeproctext]{ref-MakowskiBen-Shachar2019-bayestestR}
Makowski, D., Ben-Shachar, M. S., \& Lüdecke, D. (2019). {bayestestR:
Describing Effects and their Uncertainty, Existence and Significance
within the Bayesian Framework}. \emph{Journal of Open Source Software},
\emph{4}(40), 1541. \url{https://doi.org/10.21105/joss.01541}

\bibitem[\citeproctext]{ref-McElreath2016-Statistical-Ret}
McElreath, R. (2016/2020). \emph{Statistical rethinking}. Chapman; Hall.

\bibitem[\citeproctext]{ref-MoreyRomeijn2016-philosophyOfBFs}
Morey, R. D., Romeijn, J.-W., \& Rouder, J. N. (2016). The philosophy of
bayes factors and the quantification of statistical evidence.
\emph{Journal of Mathematical Psychology}, \emph{72}, 6--18.
\url{https://doi.org/10.1016/j.jmp.2015.11.001}

\bibitem[\citeproctext]{ref-Oh2014-Bayesian-compar}
Oh, M.-S. (2014). Bayesian comparison of models with inequality and
equality constraints. \emph{Statistics and Probability Letters},
\emph{84}, 176--182. \url{https://doi.org/10.1016/j.spl.2013.10.005}

\bibitem[\citeproctext]{ref-R_program}
R Core Team. (2025). \emph{R: A language and environment for statistical
computing}. R Foundation for Statistical Computing.
\url{https://www.R-project.org/}

\bibitem[\citeproctext]{ref-SanfordHalberda2023-A-Shared-Intuit}
Sanford, E. M., \& Halberda, J. (2023). A shared intuitive
(mis)understanding of psychophysical law leads both novices and educated
students to believe in a just noticeable difference (JND). \emph{Open
Mind}, \emph{7}, 785--801. \url{https://doi.org/10.1162/opmi_a_00108}

\bibitem[\citeproctext]{ref-scheel2022most}
Scheel, A. M. (2022). Why most psychological research findings are not
even wrong. \emph{Infant and Child Development}, \emph{31}(1), e2295.

\bibitem[\citeproctext]{ref-turner2019perception}
Turner, D. R., Bradlow, A. R., \& Cole, J. S. (2019). Perception of
pitch contours in speech and nonspeech. \emph{INTERSPEECH}, 2275--2279.

\bibitem[\citeproctext]{ref-VandekerckhoveMatzke2013-Model-Compariso}
Vandekerckhove, J., Matzke, D., \& Wagenmakers, E.-J. (2015). Model
comparison and the principle of parsimony. In J. Busemeyer, J. Townsend,
Z. J. Wang, \& A. Eidels (Eds.), \emph{Oxford handbook of computational
and mathematical psychology} (pp. 300--319). Oxford University Press.

\bibitem[\citeproctext]{ref-WagenmakersLodewyckx2010-Bayesian-hypoth}
Wagenmakers, E.-J., Lodewyckx, T., Kuriyal, H., \& Grasman, R. (2010).
Bayesian hypothesis testing for psychologists: {A} tutorial on the
{S}avage--{D}ickey method. \emph{Cognitive Psychology}, \emph{60},
158--189.

\bibitem[\citeproctext]{ref-WetzelsGrasman2010-An-encompassing}
Wetzels, R., Grasman, R. P. P. P., \& Wagenmakers, E.-J. (2010). An
encompassing prior generalization of the savage--dickey density ratio.
\emph{Computational Statistics and Data Analysis}, \emph{54},
2094--2102. \url{https://doi.org/10.1016/j.csda.2010.03.016}

\bibitem[\citeproctext]{ref-winter_Linear_preprint_2013}
Winter, B. (2013). \emph{Linear models and linear mixed effects models
in {R} with linguistic applications} (arXiv:1308.5499). arXiv.
\url{https://doi.org/10.48550/arXiv.1308.5499}

\bibitem[\citeproctext]{ref-winter2019statistics}
Winter, B. (2019). \emph{Statistics for linguists: An introduction using
r}. Routledge.

\bibitem[\citeproctext]{ref-winter-grawunder_Phonetic_journalarticle_2012}
Winter, B., \& Grawunder, S. (2012). The phonetic profile of {Korean}
formal and informal speech registers. \emph{Journal of Phonetics},
\emph{40}(6), 808--815. \url{https://doi.org/10.1016/j.wocn.2012.08.006}

\bibitem[\citeproctext]{ref-woensdregt2024lessons}
Woensdregt, M., Fusaroli, R., Rich, P., Modrák, M., Kolokolova, A.,
Wright, C., \& Warlaumont, A. S. (2024). Lessons for theory from
scientific domains where evidence is sparse or indirect.
\emph{Computational Brain \& Behavior}, \emph{7}(4), 588--607.

\end{CSLReferences}

\section{Session information}\label{session-information}

\begin{verbatim}
R version 4.5.1 (2025-06-13)
Platform: aarch64-apple-darwin20
Running under: macOS Sequoia 15.6.1

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: Europe/Berlin
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] bayestestR_0.16.1 patchwork_1.3.2   tidybayes_3.0.7   brms_2.23.0      
 [5] Rcpp_1.1.0        ggdist_3.3.3      lubridate_1.9.4   forcats_1.0.1    
 [9] stringr_1.5.2     dplyr_1.1.4       purrr_1.1.0       readr_2.1.5      
[13] tidyr_1.3.1       tibble_3.3.0      ggplot2_4.0.0     tidyverse_2.0.0  

loaded via a namespace (and not attached):
 [1] svUnit_1.0.6          tidyselect_1.2.1      farver_2.1.2         
 [4] loo_2.8.0             S7_0.2.0              fastmap_1.2.0        
 [7] tensorA_0.36.2.1      digest_0.6.37         timechange_0.3.0     
[10] lifecycle_1.0.4       StanHeaders_2.32.10   processx_3.8.6       
[13] magrittr_2.0.4        posterior_1.6.1       compiler_4.5.1       
[16] rlang_1.1.6           tools_4.5.1           utf8_1.2.6           
[19] yaml_2.3.10           data.table_1.17.8     knitr_1.50           
[22] labeling_0.4.3        bridgesampling_1.1-2  bit_4.6.0            
[25] pkgbuild_1.4.8        curl_7.0.0            RColorBrewer_1.1-3   
[28] cmdstanr_0.9.0        abind_1.4-8           withr_3.0.2          
[31] datawizard_1.2.0      grid_4.5.1            stats4_4.5.1         
[34] inline_0.3.21         scales_1.4.0          tinytex_0.57         
[37] insight_1.4.0         cli_3.6.5             mvtnorm_1.3-3        
[40] rmarkdown_2.30        crayon_1.5.3          generics_0.1.4       
[43] RcppParallel_5.1.11-1 rstudioapi_0.17.1     tzdb_0.5.0           
[46] rstan_2.32.7          bayesplot_1.14.0      parallel_4.5.1       
[49] matrixStats_1.5.0     vctrs_0.6.5           Matrix_1.7-3         
[52] jsonlite_2.0.0        hms_1.1.4             arrayhelpers_1.1-0   
[55] bit64_4.6.0-1         logspline_2.1.22      glue_1.8.0           
[58] codetools_0.2-20      ps_1.9.1              distributional_0.5.0 
[61] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.1       
[64] pillar_1.11.1         htmltools_0.5.8.1     Brobdingnag_1.2-9    
[67] R6_2.6.1              vroom_1.6.6           evaluate_1.0.5       
[70] lattice_0.22-7        backports_1.5.0       rstantools_2.5.0     
[73] gridExtra_2.3         coda_0.19-4.1         nlme_3.1-168         
[76] checkmate_2.3.3       xfun_0.53             pkgconfig_2.0.3      
\end{verbatim}

\begin{verbatim}
[[1]]
Bürkner P (2017). "brms: An R Package for Bayesian Multilevel Models
Using Stan." _Journal of Statistical Software_, *80*(1), 1-28.
doi:10.18637/jss.v080.i01 <https://doi.org/10.18637/jss.v080.i01>.

Bürkner P (2018). "Advanced Bayesian Multilevel Modeling with the R
Package brms." _The R Journal_, *10*(1), 395-411.
doi:10.32614/RJ-2018-017 <https://doi.org/10.32614/RJ-2018-017>.

Bürkner P (2021). "Bayesian Item Response Modeling in R with brms and
Stan." _Journal of Statistical Software_, *100*(5), 1-54.
doi:10.18637/jss.v100.i05 <https://doi.org/10.18637/jss.v100.i05>.

[[2]]
Makowski D, Ben-Shachar M, Lüdecke D (2019). "bayestestR: Describing
Effects and their Uncertainty, Existence and Significance within the
Bayesian Framework." _Journal of Open Source Software_, *4*(40), 1541.
doi:10.21105/joss.01541 <https://doi.org/10.21105/joss.01541>,
<https://joss.theoj.org/papers/10.21105/joss.01541>.

[[3]]
Kay M (2024). _tidybayes: Tidy Data and Geoms for Bayesian Models_.
doi:10.5281/zenodo.1308151 <https://doi.org/10.5281/zenodo.1308151>, R
package version 3.0.7, <http://mjskay.github.io/tidybayes/>.

[[4]]
Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,
Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E,
Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi
K, Vaughan D, Wilke C, Woo K, Yutani H (2019). "Welcome to the
tidyverse." _Journal of Open Source Software_, *4*(43), 1686.
doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.

[[5]]
Kay M (2024). "ggdist: Visualizations of Distributions and Uncertainty
in the Grammar of Graphics." _IEEE Transactions on Visualization and
Computer Graphics_, *30*(1), 414-424. doi:10.1109/TVCG.2023.3327195
<https://doi.org/10.1109/TVCG.2023.3327195>.

Kay M (2025). _ggdist: Visualizations of Distributions and
Uncertainty_. doi:10.5281/zenodo.3879620
<https://doi.org/10.5281/zenodo.3879620>, R package version 3.3.3,
<https://mjskay.github.io/ggdist/>.
\end{verbatim}






\end{document}
