---
title: "How to test hypothesis using Bayes Factor in behavioral sciences"
shorttitle: "Test Bayes Factor"
number-sections: true
author:
  - name: Timo B. Roettger
    corresponding: true
    orcid: 0000-0003-1400-2739
    email: timo.roettger@iln.uio.no
    affiliations:
      - name: University of Oslo
        department: Department of Linguistics & Scandinavian Studies
        city: Oslo
        country: Norway
  - name: Michael Franke
    corresponding: false
    #orcid: 0000-0003-1400-2739
    email: mchfranke@gmail.com
    affiliations:
      - name: University of Tübingen
        department: Department of Linguistics
        city: Tübingen
        country: Germany
author-note:
  status-changes: 
    affiliation-change: null
    deceased: null
  disclosures:
    study-registration: null
    data-sharing: null
    related-report: null
    conflict-of-interest: The authors have no conflict of interest to declare.
    financial-support: null
    gratitude: null
    #authorship-agreements: Conceptionalization, Methodology, Validation, Formal Analysis, Review & Editing of Manuscript, Data Curation - TBR. & DLJE; Software, Investigation - DLJE; Writing of Original Draft, Visualization, Supervision - TBR.
abstract: "Recent times have seen a surge of Bayesian inference across the behavioral sciences. However, the process of testing hypothesis is often conceptually challenging or computationally costly. This tutorial provides an accessible, non-technical introduction that covers the most common scenarios in experimental sciences: Testing the evidence for an alternative hypothesis using Bayes Factor through the Savage Dickey approximation. This method is conceptually easy to understand and computatioanlly cheap."
keywords: [statistics, Bayes, Bayes Factor, Savage Dickey, hypothesis testing, ROPE]
bibliography: bibliography.bib
format:
  apaquarto-docx: default
  apaquarto-html: default
  apaquarto-pdf:
    # Can be jou (journal), man (manuscript), stu (student), or doc (document)
    documentmode: jou
    keep-tex: true
#header-includes: \usepackage{annotate-equations}
execute:
  echo: false
editor: 
  markdown: 
    wrap: sentence
---

# Introduction

To date, the most common quantitative approach across the experimental sciences is to run an experiment with one or more predictors and statistically test if there is evidence that these predictors affect the measured variables.
Traditionally, this process has been done by form of null hypothesis significance testing.
Over the last decade or so, however, we have seen more and more statistical approaches within an alternative inferential framework: Bayesian inference.
Testing hypothesis within the Bayesian framework is often considered either conceptually challenging, computationally too costly, or both.
This tutorial provides an accessible, non-technical introduction to Bayesian hypothesis testing that is easy to understand and computationally cheap.

# Motivation and intended audience

This tutorial provides a very basic introduction to the topic using R (R Core Team, 2025).
We wrote this tutorial with a particular reader in mind.
If you have used R before and if you have a basic understanding of linear regression, and Bayesian inference, this tutorial is for you.
We will remain mostly conceptual to provide you with a conceptual tool to approach hypothesis testing within Bayesian inference.
The form of hypothesis testing that we would like to introduce to you is, however, different from the traditional null hypothesis significance testing in that it requires more decisions about the quantitative nature of your data.
More thinking so to speak.
This is not a bug but, at least for us, a feature that will allow you to understand both your data and what you can learn from them better.
This work stands on the shoulders of giants with many fantastic resources out there.
Importantly this tutorial and the accompanying scripts will make use of a few wonderful R package: - we use the extraordinary brms pacakge to run our Bayesian models, written by Paul Buerkner (2016).
- we use the bayestestR package to calculate the Bayes Factors, written by Makowski et al. (2019) - we use the ...

If you don’t have any experience with regression modeling, you will probably still be able to follow, but you might also want to consider doing a crash course.
To bring you up to speed, we recommend the excellent tutorial by Bodo Winter (2013) on mixed eﬀects regression in a non-Bayesian —a.k.a.
frequentist—paradigm.
To then make the transition to Bayesian versions of these regression models, we shamelessly suggest our own tutorial on "Bayesian Regression for Factorial Designs" as a natural follow-up using the same data and Winter.
In a sense, the present tutorial on hypothesis testing could be considered the long-awaited sequel of the series started by Winter, continuing to use the original data.

To actively follow this tutorial, you should have R installed on your computer (https://www.r-project.org).
Unless you already have a favorite editor for tinkering with R scripts, we recommend to try out RStudio (https://www.rstudio.com).
You will also need some packages, which you can import with the following code:

```{r libraries}

# package for convenience functions (e.g. plotting)
library(tidyverse)

# package for Bayesian regression modeling
library(brms)

# package for posterior wrangling and plotting
library(tidybayes)

# package for BF calculation and plotting
library(bayestestR)
library(see)

# project colors
project_colors = c(
  "#7581B3", "#99C2C2", "#C65353", "#E2BA78", "#5C7457", "#575463",
  "#B0B7D4", "#66A3A3", "#DB9494", "#D49735", "#9BB096", "#D4D3D9",
  "#414C76", "#993333"
  )

```

# Data, research questions & hypotheses

This tutorial looks at a data set relevant for investigating whether voice pitch diﬀers across social contexts in Korean.
Korean is a language in which the relationship between speakers plays a central role.
The way Korean speakers use speak depends for example on whether they are in a formal (e.g. during a consultation with a professor) or an informal context (e.g. chatting with a friend about the holidays) (e.g. Winter et al. 201#)

To load the data into your R environment, run the following code

```{r libraries}

# TO DO: STORE ONLINE
# TO DO: SIMPLIFY DATA
polite = read_csv("../data/polite.csv") |> 
  # remove men
  filter(gender == "F") |> 
  # calculate semitones (reference 50 Hz)
  mutate(pitch_ST = 12 * log2(pitch / 50))

polite

```

This data set contains information about diﬀerent subjects, with an anonymous identifier stored in variable `subject.` In this tutorial we will only be looking at female speakers.
Subjects produced diﬀerent sentences, and the experiment manipulated whether the sentence was produced in a `formal` or an `informal` context, indicated by the variable `context.` Crucially, each row contains a measurement of pitch in Hz stored in the variable `pitch`.

For most analyses of behavioral experiments, researchers are interested in whether an outcome variable is affected by a manipulated variable and if so how the outcome variable is affected by it.
In this case, Winter et al. (201#) wanted to test whether pitch is affected by the social context of the utterance.

As a first step, we can explore this question visually:

```{r descriptive-dataviz}

politeF |> 
  # aggregate mean values for context
  group_by(context) |> 
  summarize(pitch_ST = mean(pitch_ST, na.rm = TRUE)) |> 
  ggplot(aes(y = context, 
             x = pitch_ST, 
             fill = context,
             colour = context)) + 
  # plot all data as semitransparent points
  geom_point(data = polite,
             position = position_dodge(0.5), 
             alpha = 0.5, 
             size = 3) +
  # plot all data as density ridges
  geom_density_ridges(data = polite,
                      alpha = 0.5,
                      scale = 0.5) +
  # plot mean values per condition as large points
  geom_point(position = position_dodge(0.5), 
             pch = 21, 
             colour = "black",
             size = 5) +
  scale_x_continuous(limits = c(10,40)) +
  scale_colour_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  scale_fill_manual(breaks = c("informal", "formal"),
                      values = c(project_colors[1], project_colors[3])) +
  labs(x = "\npitch in semitones",
       y = "social context\n") +
  theme_minimal() +
  theme(legend.position = "none")

```

Figure 1 displays the mean pitch values for each sentence (semi-transparent points) across contexts.
The solid points indicate the average pitch values across all sentences and speakers.
Looking at the plot, we can see that pitch values from utterances from formal contexts are on average slightly lower than those from informal contexts. The red distribution is slightly shifted to the left of the blue distribution by around 1.3 semitones. In other words, speakers tend to slightly lower their voice pitch when speaking in a formal context. But there is also a lot of overlap between the two contexts. As Bayesians, we would like to translate the data into an expression of evidence: does the data provide evidence for our research hypotheses? 

Let us run a Bayesian linear model to approach an answer to this question:

```{r priors}
#| output: false

# define linear model formula
# here we simplify the data set and predict pitch by context and allow for that relationship to vary between subjects
formula <- bf(pitch_ST ~ context + (1 + context | subject))

# get prior
get_prior(formula, politeF)

# pick weakly informative priors
priors <- c(prior(normal(28, 3), class = Intercept),
            # pick a very lenient prior for the context effect that assumes a normal distribution centered on zero with a standard deviation of 1
            prior(normal(0, 1), class = b, coef = "contextinformal"),
            # some sensible priors for the correlation coefficient and the variation between subjects
            prior(lkj(2), class = cor),
            prior(normal(0, 2), class = sd))

```


## What is Bayes Factor

## Approximating BF with Savage Dickey

Politeness Data

## BF for point null

## Sensitivity analysis for different priors

## BF for a Region of Practical Equivalence (ROPE)

## How to chose a ROPE?

-   theoretically derived?
    -   communicatively relevant?
-   standardized effect sizes?

## Sensitivity analysis for different priors and ROPEs

## Write up

Do’s Do think think about sensible priors think about sensible ropes think about the smallest effect sizes of interest instead of testing point-0

Don’ts Don’t fall into the trap of discrete thresholds.
Don’t hack ropes
